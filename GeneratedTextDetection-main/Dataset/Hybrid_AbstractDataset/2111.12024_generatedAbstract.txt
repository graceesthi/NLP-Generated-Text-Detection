Neural network-based methods for solving differential equations have been gaining traction. They work by improving the differential equation residuals of a neural network on a sample of points in each iteration. However, most of them employ standard sampling schemes like uniform or perturbing equally spaced points. We present a novel method for improving the posterior distribution of neural networks based on stochastic gradient descent. This approach has the advantage that it is very robust when applied to a distributed model, and is able to cope with a large scale dataset in the shortest possible time frame. Finally, we demonstrate that this scheme outperforms pre-existing schemes by comparing both on a number of problems.