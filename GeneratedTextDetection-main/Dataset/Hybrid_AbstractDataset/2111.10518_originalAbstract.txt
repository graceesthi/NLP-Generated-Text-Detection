There has been growing interest in the development and de- ployment of autonomous vehicles on modern road networks over the last few years, encouraged by the empirical suc- cesses of powerful artificial intelligence approaches (AI), es- pecially in the applications of deep and reinforcement learn- ing. However, there have been several road accidents with “autonomous” cars that prevent this technology from being publicly acceptable at a wider level. As AI is the main driv- ing force behind the intelligent navigation systems of such ve- hicles, both the stakeholders and transportation jurisdictions require their AI-driven software architecture to be safe, ex- plainable, and regulatory compliant. We present a framework that integrates autonomous control, explainable AI architec- ture, and regulatory compliance to address this issue and fur- ther provide several conceptual models from this perspective, to help guide future research directions.