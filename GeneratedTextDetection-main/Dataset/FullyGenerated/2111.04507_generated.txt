Abstract. Ontology-based approach to the Natural Language Understanding (NLU) processing allows to improve questions answering quality in dialogue sys- tems. We describe our NLU engine architecture and evaluate its implementation. The engine transforms userÃÂ¢ÃÂÃÂs input into the SPARQL SELECT, ASK or INSERT query to the knowledge graph provided by the ontology-based data virtualization platform. The transformation is based on the lexical level of the knowledge graph built according to the Ontolex ontology. The described approach can be applied for graph data population tasks and to the question answering systems implementation, including chat bots. We describe the dialogue engine for a chat bot which can keep the conversation context and ask clarifying questions, simulating some aspects of the human logical thinking. Our approach uses graph-based algorithms to avoid gathering datasets, required in the neural nets-based approaches, and provide better explainability of our mod- els. Using question answering engine in conjunction with data virtualization layer over the corporate data sources allows extracting facts from the structured data to be used in conversation. Keywords: natural language understanding, ontology, Ontolex, data virtualization. Introduction The corporate automated system users expect them to be Ã¢ÂÂintellectualÃ¢ÂÂ enough to give precise answers to their questions. It implies that a system must give meaningful answers in the dialogue with a user and ask clarifying questions as a human would do. To achieve that, the system must deal with the structured representation of each ques- tion and answer of a dialogue, as well as with a structured data required to give an answer. The knowledge graphs (KGs) are one of the most popular ways to represent the complex structured information. KGs can be populated with information by data mining from text sources or struc- tured data sets Ã¢ÂÂ for example, the business application databases in the corporate envi- ronment. Some aspects of the corporate KGs assembly are considered in [Noy, 2019]. Our task is to develop the complex solution (framework) for the corporate use which will provide: 1) Conceptual model construction for representing the usersÃ¢ÂÂ domain knowledge. We do not have a task of automated ontology assembly or enrichment because in the corporate projects the ontology is predominantly composed manually. 2) Disparate corporate data sets into a virtual Knowledge Graph. 3) The natural language tools for user interaction with KG. The domain ontology composition and the virtual KG assembly are out of scope of this paper (see: [Gorshkov, 2021]). We will focus on the methods of userÃ¢ÂÂs natural lan- guage question transformation into the SPARQL query to the knowledge graph, and the dialogue system implementation. Task definition We consider the KG question-answering and the task of facts extraction from the natural language text as the task of the representing the text meaning in the form of the graph restricted by a conceptual model. In this paper we focus on the description of the dialogue system which transforms a userÃ¢ÂÂs question into a query to the graph. The func- tional requirements to this system are: 1) It must find the class or property which instances would be an answer to the userÃ¢ÂÂs question and query the KG to find the appropriate entities matching cri- teria defined in the question. 2) The systemÃ¢ÂÂs answer should be precise, not probabilistic. The system must be able to prove that the found objects are the answers to the userÃ¢ÂÂs query, includ- ing visualization of the relations chain that led to these objects. 3) If there is no unambiguous answer to the userÃ¢ÂÂs query, the system should ask clarifying questions. 4) The system should answer userÃ¢ÂÂs clarifying questions, which may be asked if the answer is not comprehensive for the user. It means that the system shall keep the conversation context, i.e., the objects and relations mentioned in the previous questions and answers. These requirements cannot be fulfilled today using the neural networks only. The researchers [Thorne, 2021] note that the contemporary NL processing models cannot scale to non-trivial databases nor answer set-based and aggregation queries. Any neural network model output is probabilistic by its nature and cannot be provided with the proof of correctness. We believe, following [Weikum, 2021], that machine knowledge and machine learning complement and strengthen each other. We aimed to combine optimally the strong points of both approaches, machine learning and logical inference, when designing the text processing pipeline. The neural networks are effective in knowledge graph query answering (KGQA) when dealing with thegraphs containing ambiguities, such as DBPedia. The big datasets are required to train such models. This is often impossible when dealing with corporate tasks in the specific and narrow domains. Due to these factors, we have set a goal of creating the explainable and fully controlled tool. Let us describe a domain which we will use as a field for evaluating our solution. Consider the sample industrial enterprise which is composed of the functional units and sites. Each unit and site have a person or organizational unit which is responsible for some aspect of its safety (fire, industrial, etc.). All this information is gathered into a virtual Knowledge Graph, which can be populated with information by data mining from text sources or struc- tured data sets Ã¢ÂÂ for example, the business application databases in the corporate envi- ronment. The domain ontology composition and the virtualization projects are out of scope of this paper (see: [Gorshkov, 2021]). We will focus on the methods of userÃ¢ÂÂs natural lan- guage question transformation into the SPARQL query to the knowledge graph, and the dialogue system implementation. Task definition We consider the KG question-answering and the task of facts extraction from the natural language text as the task of the representing the text meaning in the form of the graph restricted by a conceptual model. In this paper we focus on the description of the dialogue system which transforms a userÃ¢ÂÂs question into a query to the graph. The func- tional requirements to this system are: 1) It must find the class or property which instances would be an answer to the userÃ¢ÂÂs question and query the KG to find the appropriate entities matching cri- teria defined in the question. 2) The systemÃ¢ÂÂs answer should be precise, not probabilistic. The system must be able to prove that the found objects are the answers to the userÃ¢ÂÂs query, includ- ing visualization of the relations chain that led to these objects. 3) If there is no unambiguous answer to the user query, the system should ask clarifying questions. 4) The system should answer userÃ¢ÂÂs clarifying questions, which may be asked if the answer is not comprehensive for the user. It means that the system shall keep the conversation context, i.e., the objects and relations mentioned in the previous questions and answers. These requirements cannot be fulfilled today using the neural networks only. The researchers [Thorne, 2021] note that the contemporary NL processing models cannot scale to non-trivial databases nor answer set-based and aggregation queries. Any neural network model output is probabilistic by its nature and cannot be provided with the proof of correctness. We believe, following [Weikum, 2021], that machine knowledge and machine learning complement and strengthen each other. We aimed to combine optimally the strong points of both approaches, machine learning and logical inference, when designing the text processing pipeline. The neural networks are effective in knowledge graph query answering (KGQA) when dealing with the big graphs containing ambiguities, such as DBPedia. The big datasets are required to train such models. This is often impossible when dealing with corporate tasks in the specific and narrow domains. Due to these factors, we have set a goal of creating the explainable and fully controlled tool. Let us describe a domain which we will use as a field for evaluating our solution. Consider the sample industrial enterprise which is composed of the functional units and sites. Each unit and site have a person or organizational unit which is responsible for some aspect of its safety (fire, industrial, etc.). All this information is gathered into a virtual Knowledge Graph, which can be populated with information by data mining from text sources or struc- tured data sets Ã¢ÂÂ for example, the business application databases in the corporate envi- ronment. The domain ontology composition and the virtualization projects are out of scope of this paper (see: [Gorshkov, 2021]). We will focus on the methods of userÃ¢ÂÂs natural lan- guage question transformation into the SPARQL query to the knowledge graph, and the dialogue system implementation. 