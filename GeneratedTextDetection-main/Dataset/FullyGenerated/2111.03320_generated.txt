ABSTRACT State-of-the-art approaches for metaphor detection compare their literal - or core - meaning and their contextual meaning using sequential metaphor classifiers based on neural networks. The signal that represents the literal meaning is often represented by (non-contextual) word embeddings. However, metaphorical expressions evolve over time due to various reasons, such as cultural and societal impact. Metaphorical expressions are known to co-evolve with language and literal word meanings, and even drive, to some extent, this evolution. This rises the question whether different, possibly time-specific, representations of literal meanings may impact on the metaphor detection task. To the best of our knowledge, this is the first study which examines the metaphor detection task with a detailed explorative analysis where different temporal and static word embeddings are used to account for different representations of literal meanings. Our experimental analysis is based on three popular benchmarks used for metaphor detection and word embeddings extracted from different corpora and temporally aligned to different state-of-the-art approaches. The results suggest that different word embeddings do impact on the metaphor detection task and some temporal word embeddings slightly outperform static methods on some performance measures. However, results also suggest that temporal word embeddings may provide representations of wordsÃ¢ÂÂ core meaning even too close to their metaphorical meaning, thus confusing the classifier. Overall, the interaction between temporal language evolution and metaphor detection appears tiny in the benchmark datasets used in our experiments. This suggests that future work for the computational analysis of this important linguistic phenomenon should first start by creating a new dataset where this interaction is better represented. Keywords Metaphor Detection ÃÂ· Temporal Word Embeddings ÃÂ· Word Embeddings Introduction Accounting for figurative language is one of the key challenges in Natural Language Processing (NLP). Many recent methods have proposed solutions to this problem based on machine learning methods [Recupero et al., 2019, Shutova, 2015, Leong et al., 2020]. Figurative language often contains metaphorical expressions which map one concept from a source domain to another concept in a target domain. For instance, in the sentence Ã¢ÂÂThe wheels of StalinÃ¢ÂÂs regime were well-oiled and already turning", a political system (target concept) is viewed in terms of a mechanism (source concept) which can function, break, have wheels, etc. This association allows us to transfer knowledge from the domain of mechanical engineering to that of politics. Therefore, political systems are thought about in terms of mechanisms, leading to multiple metaphorical expressions. The phenomenon of source-target domain mapping was first introduced by George Lakoff known as Conceptual Metaphor Theory [Lakoff and Johnson, 1980]. Due to previously defined characteristics, the presence of metaphorical expression in text causes misinterpretation in the algorithms such as machine translation or sentiment analysis [Saif Mohammad, 2016]. For example, in machine translation, the text may be translated literally choosing inappropriate words, instead of those ones that capture the metaphorical meaning. Similarly, in the case of sentiment analysis, the polarity of the sentences can be misinterpreted and even inverted due to the presence of metaphors. Therefore, several studies have addressed the problem of detecting metaphors in text. The studies addressing the metaphor detection problem in the last decade [Shutova, 2015] usually exploit word embeddings to encode word meaning. Word embeddings are distributed representations, i.e., vectors, derived from the usage of words in large text corpora: words occurring in similar contexts have similar meanings and are eventually close to each other in a vector space [Almeida and XexeÃÂo, 2019]. In metaphor detection, these vector-based representations can be used as signals to classify sentences or individual words as being used with a metaphorical meaning or not. The key intuition is to recognize that words are used in a context that is different from their usual context, i.e., that their usage in a specific context significantly differs from their usage in their most frequent contexts, which qualify their literal meanings. In the previous example, Ã¢ÂÂwheels" is collocated close to Ã¢ÂÂStalin" and Ã¢ÂÂregime", which define a context different from the contexts in which it usually appears, i.e., in the domain of mechanical engineering. In other words, the classifier, usually implemented as a neural network, is expected to compare literal word meanings with word meanings in specific contexts to detect if in that context a metaphor is used. Most of the recent approachestherefore combined non-contextual and contextual word embeddings to provide signals for this comparison (e.g., exploiting the concatenation of non-contextualized and contextualized word vectors) [Mao et al., 2019, Swarnkar and Singh, 2018]. For example, Mao et al. [2019], Gulordava and Baroni [2011], Tomas Mikolov and Dean [2013a] combine non-contextual GloVe embeddings [Jeffrey Pennington, 2014] with contextual ELMo embeddings [Peters M, 2018] within a BiLSTM neural network for sequence labelling. Glove embeddings account for literal word meanings, while ELMo embeddings account for contextual word meanings. The network tries to learn when the comparison between the two vectors indicates a metaphorical word usage. Word embedding techniques such as GloVe or Word2Vec [Tomas Mikolov and Dean, 2013a] are static embeddings that associate each word with one, context independent, representation. Contextual word embeddings, such as ELMo and BERT [Devlin et al., 2018], associate each word with one representation per sentence. For example, in the following two sentences: Ã¢ÂÂApple sells phonesÃ¢ÂÂ and Ã¢ÂÂI eat an appleÃ¢ÂÂ, contextual embeddings will represent Ã¢ÂÂappleÃ¢ÂÂ differently in each sentence, while static embedding can not distinguish the semantic difference between the two references of Ã¢ÂÂappleÃ¢ÂÂ. Usually, the latter represents a word with its core meaning, i.e., with the meaning in those contexts that are more frequent in the corpus used to train the embeddings (when more meanings compete as core meanings, words may be associated with vectors that mediate across contexts). An important linguistic phenomenon that is not accounted in static and contextual word embeddings is language evolution. While contextual word embeddings are expected to be sentence-specific and thus de-contextualized with respect to time, static word embeddings are expected to account for core meanings - and literal meanings in metaphor detection. Core meanings of course change over time and several approaches have been proposed to capture this changes [William L. Hamilton, 2018]. The trait of evolution of the meaning over time is also shared by metaphorical expressions which can be due to various reasons such as cultural and societal impact. Metaphorical expressions are known to co-evolve with language and literal word meanings derive this evolution to some extent [Smith and HoÃÂfler, 2015a, Aitchison, 2003]. This leads to the question whether different, possibly time-specific, representations of literal meanings impact the task of metaphor detection. In conclusion, if metaphor detection approaches tend to compare a sentence-specific and a literal meaning, we must be aware that literal meaning as accounted in static word embeddings 1) depends on the corpus and method used to train the embeddings and 2) evolve over time. To this end, the current empirical study focuses on analyzing the impact of different embeddings accounting for literal word meaning on the task of metaphor detection. In particular, we want to study the interactions between metaphor detection approaches and different word embeddings used to account for the literal meaning of words in these approaches. We want to dedicate a special attention to possible interactions between metaphor detection and time-specific (nonÃ¢ÂÂcontextual) word representations used to account for literal meanings at different times. To the best of our knowledge, this is the first study seeking for interactions between time-dependent word representations and metaphor detection approaches. The empirical study discussed in this paper aims to make a first step into addressing the co-evolution of metaphors and language evolution that is known to be an important factor for language evolution itself [Smith and HoÃÂfler, 2015a, Aitchison, 2003]. The methodology adopted in our study consists in following protocol. First, we select a state-of-the-art Recurrent Neural Networks (RNN)-based model [Ge Gao and Zettlemoyer, 2018] for metaphor detection which uses static word embeddings to account for literal word meaning; the model performs metaphor detection as a sequence classification task where each word occurrence is labeled as either a metaphor usage or a literal usage. Second, we select three benchmark data sets widely used to evaluate the performance of metaphor detection approaches. Third, we feed the RNN-based model with literal meaning vectors obtained from different (non contextual) word embeddings spaces; these spaces differs for the corpora used to train them and, especially includeword embeddings computed for different decades and aligned with state-of-the-art alignment methods, such as Procrustes [Edouard Grave, 2018] and the Compass method (first referred to as Temporal Word Embeddings with a Compass [Di Carlo et al., 2019] - TWEC and later as Compass-aligned Distributional Embeddings [Bianchi et al., 2020]. The experimental results indicate that different word embeddings impact the metaphor detection task and some temporal word embeddings slightly outperform static methods on some performance measures. These quantitative results are then explained with the help of a qualitative analysis of the predictions made by the models. During this analysis, some interesting recurring patterns were observed. Some patterns concern the interactions between literal meanings and domains of discourse. For example, in sentences containing correctly identified metaphors, the topics related to economics, politics, and emotions are the most recurring ones. Besides, verbs having a literal meaning characterized by physical connotations, often assume figurative meanings when used in the sentences related to the previously listed contexts. Some patterns concern indeed the interaction between time and language. Studying the predictions obtained with the embeddings of one specific time period, we noticed that none of the sentences belonging to the Ã¢ÂÂnews" domain of the VUA dataset were correctly predicted. This could indicate that for that specific time period (1990 decade), wordsÃ¢ÂÂ representations of that domain are biased towards their metaphorical meaning, and this would prevent the neural networks from correctly identifying the metaphors. Furthermore, if temporal word embeddings provided wordsÃ¢ÂÂ representations that are more inclined towards their literal core meaning (and not the metaphorical one), models exploiting them would correctly identify metaphors more easily. One way to investigate these hypotheses further is to explore the nearest neighbors of a word in the word embeddings used in a figurative way inside a sentence, both in a static (atemporal) word embedding space, e.g., obtained with GloVe [Jeffrey Pennington, 2014] and in a decade-specific temporal space, e.g., obtained from the CoHa1 corpus with Procrustes [Edouard Grave, 2018].This pattern is highlighted by the following sentence example: Ã¢ÂÂThe virus attacked Argonne National Laboratory outside Chicago starting at 11.54 pm EST Wednesday and throughout the night". If we investigate the ten nearest neighbors of Ã¢ÂÂvirus", in the temporal embedding we find words such as Ã¢ÂÂinfection, respiratory and organism", while in the atemporal one there are for example Ã¢ÂÂmalware and spyware", that diverge from the core literal meaning and are related to a modern connotation of the word. When exploiting the temporal word embedding, the model is able to understand that the Ã¢ÂÂvirus" in this sentence is a computer one, and therefore that it is used in a metaphorical way along with the verb Ã¢ÂÂattacked". The paper is organized as follows: Section 2 discusses the related work about metaphor detection as well as temporal word embeddings. Section 3 discusses the methodology followed while Section 4 shows the experimental results of the paper. Finally, Section 5 concludes the paper. Discussion and Conclusion In the previous sections, we analyzed the results of our work. As an additional step to evaluate the impact of temporal embeddings on the evolution of language and the meaning of the words, we also performed our experiments using the words with the biggest semantic shift across time. The wordsÃ¢ÂÂ list was retrieved from the SemEval 2020 Task 1: Unsupervised Lexical Semantic Change Detection Competition2.We tried building a custom dataset by searching for metaphorical and literal sentences that would contain all these words so that it would be possible to perform metaphor detection tasks exploiting different temporal embeddings. Unfortunately, this final experiment was not feasible, due to the fact that there were not enough metaphorical statements in the competition dataset or in the state-of-the-art ones with the aforementioned words being used in a proper way. We performed metaphor detection as a sequence classification task in order to identify words with figurative meanings inside sentences. This approach allowed us to take advantage of different types of word representations, especially temporal ones, and evaluate their impact on metaphor detection. Looking at the numerous and diversified results, we can affirm that temporal word embeddings do generally improve the performance of the task of metaphor detection, however, their overall impact is rather limited. Besides, independently from the absolute performance, the interaction effect between the specificity of the embeddings (especially their temporal specificity) and metaphor detection is found in the experiments conducted in this study. In fact, these experiments verify that if the core meaning of the words ofin a sentence is too similar to their figurative one in the word embedding, a metaphorical sentence could get misclassified as literal. Moreover, when temporal word embeddings provide wordsÃÂ¢ÃÂÃÂ representations that are more inclined towards their literal core meaning (and not the metaphorical one), models exploiting end up correctly identifying metaphors more easily. One way to investigate these hypotheses further is to explore the nearest neighbors of a word in the word embeddings used in a figurative way inside a sentence, both in a static (atemporal) word embedding space, e.g., obtained with GloVe [Jeffrey Pennington, 2014] and in a decade-specific temporal space, e.g., obtained from the CoHa1 corpus with Procrustes [Edouard Grave, 2018].This pattern is highlighted by the following sentence example: Ã¢ÂÂThe virus attacked Argonne National Laboratory outside Chicago starting at 11.54 pm EST Wednesday and throughout the night". If we investigate the ten nearest neighbors of Ã¢ÂÂvirus", in the temporal embedding we find words such as Ã¢ÂÂinfection, respiratory and organism", while in the atemporal one there are for example Ã¢ÂÂmalware and spyware", that diverge from the core literal meaning and are related to a modern connotation of the word. When exploiting the temporal word embedding, the model is able to understand that the Ã¢ÂÂvirus" in this sentence is a computer one, and therefore that it is used in a metaphorical way along with the verb Ã¢ÂÂattacked". The paper is organized as follows: Section 2 discusses the related work about metaphor detection as well as temporal word embeddings. Section 3 discusses the methodology followed while Section 4 shows the experimental results of the paper. Finally, Section 5 concludes the paper. Discussion and Conclusion In the previous sections, we analyzed the results of our work.