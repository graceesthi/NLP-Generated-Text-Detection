Abstract An overarching goal of natural language pro- cessing is to enable machines to communicate seamlessly with humans. However, natural language can be ambiguous or unclear. In cases of uncertainty, humans engage in an in- teractive process known as repair: asking ques- tions and seeking clarification until their uncer- tainty is resolved. We propose a framework for building a visually grounded question- asking model capable of producing polar (yes- no) clarification questions to resolve misunder- standings in dialogue. Our model uses an ex- pected information gain objective to derive in- formative questions from an off-the-shelf im- age captioner without requiring any supervised question-answer data. We demonstrate our modelÃ¢ÂÂs ability to pose questions that improve communicative success in a goal-oriented 20 questions game with synthetic and human an- swerers. Introduction Human-machine interaction relies on accurate transfer of knowledge from users. However, nat- ural language input can be ambiguous or unclear, giving rise to uncertainty. A fundamental aspect of human communication is collaborative grounding, or seeking and providing incremental evidence of mutual understanding through dialog. Specifically, humans can correct for uncertainty through cooper- ative repair (Clark, 1996; Purver et al., 2002; Arkel et al., 2020) which involves interactively asking questions and seeking clarification. Making and recovering from mistakes collaboratively through question-asking is a key ingredient in grounding meaning and therefore an important feature in di- alog systems (Benotti and Blackburn, 2021). In this work, we focus on the computational chal- lenge of generating clarification questions in visu- ally grounded human-machine interactions. One popular approach is to train an end-to-end model to map visual and linguistic inputs directly to questions (Yao et al., 2018; Das et al., 2017). This approach is heavily data-driven, requiring large annotated training sets of questions under different goals and contexts. Another approach has drawn from work on active learning and Optimal Experiment Design (OED) in cognitive science to search for questions that are likely to maximize ex- pected information gain from an imagined answerer (Wang and Lake, 2019; Lee et al., 2018; Misra et al., 2018; Rao and DaumeÃÂ III, 2018; Rothe et al., 2017;Kovashka and Grauman, 2013). Much of this work has relied on large-scale question-answer datasets (Kumar and Black, 2020; de Vries et al., 2017) for training or retrieval to propose candidate ques- tions or evaluate their expected utility. Others, like (Yu et al., 2020), derive questions from attribute annotations for domain-specific systems. In this paper, we address an open-domain setting where one cannot rely on an immediate grounding of the meaning of questions in the target domain (in contrast to end-to-end approaches, which assume examples of questions to train on, or semantic pars- ing approaches, which assume a logical form for questions). Our key contribution is a lightweight method to ground question semantics in the open image domain without observing question exam- ples. Instead, our framework builds a visually grounded question-asking model from image cap- tioning data, deriving question selection and belief updating without existing semantics. Our model generates candidate polar questions, arguably the most common form of clarification in dialogue (Stivers, 2010), by applying rule-based linguistic transformations to the outputs of a pretrained image captioner. We then use self-supervision to train a re- sponse model that predicts the likelihood of differ- ent answers. Given these predictions, we estimate the expected information gain of each question and select the question with the highest utility. We demonstrate our methodÃ¢ÂÂs ability to pose questions that improve communicative success in a question- driven communication game with synthetic and human answerers. Conclusions We introduce a question generation framework ca- pable of producing open-domain clarification ques- tions. Instead of relying on specialized question- answer training data or pre-specified question meanings, our model uses a pretrained image cap- tioner in conjunction with expected information gain to produce informative questions for unseen images. We demonstrate the effectiveness of this method in a question-driven communication game with synthetic and human answerers. We found it important to generate questions varying in speci- ficity by decomposing captioner utterances into component noun phrases. Having generated this set of potential questions, selecting based on esti- mated information gain yielded useful questions. Without seeing question examples, our framework demonstrates a capacity for generating effective clarification questions. Future research should aim to generate more diversesets, allow for more expressive answers, and address abstract properties of objects within images. One approach, as demonstrated by our preliminary work with what-questions, would be to extend our framework to incorporate additional types of wh-questions.