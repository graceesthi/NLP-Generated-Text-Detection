Through anonymisation and accessibility, social media platforms have facilitated the proliferation of hate speech, prompting increased research in developing automatic methods to identify these texts. This paper explores the classification of sexism in text using a variety of deep neural network model architectures such as Long-Short-Term Memory (LSTMs) and Convolutional Neural Networks (CNNs). These networks are used in conjunction with transfer learning in the form of Bidirectional Encoder Representations from Transformers (BERT) and DistilBERT models, along with data augmentation, to perform binary and multiclass sexism classification on the dataset of tweets and gabs from the sEXism Identification in Social neTworks (EXIST) task in IberLEF 2021. The models are seen to perform comparatively to those from the competition, with the best performances seen using BERT and a multi-filter CNN model. Data augmentation further improves these results for the multi-class classification task. This paper also explores the errors made by the models and discusses the difficulty in automatically classifying sexism due to the subjectivity of the labels and the complexity of natural language used in social media. KeywordsÃ¢ÂÂ Sexism classification, social media, natural language processing, neural networks, machine learning, BERT, transfer learning. INTRODUCTION Social media has completely altered the way communities are formed and utilised, which provides incredible advantages while also having severe repercussions. Due to the Ã¢ÂÂonline disinhibition effectÃ¢ÂÂ (Suler, 2004, p. 1), when users are provided with an anonymised and accessible platform, they engage in behaviours they would not partake in when interacting face-to-face (Wright et al., 2019). A significant example of this is the hate speech produced and propagated through social media platforms. Hate speech is defined as language which is Ã¢ÂÂinsulting, degrading, defaming, negatively stereotyping, or inciting hatred, discrimination or violence against people in virtue of their race, ethnicity, nationality, religion, sexual orientation, disability, gender identityÃ¢ÂÂ (Brown, 2017, p. 1). The prevalence of hate speech in everyday life has increased in correlation with social media usage, particularly during the COVID-19 pandemic, with internet usage levels having increased between 50% to 70% as of early April 2020 (UN Women, 2020). Online hate speech, especially targeted discrimination, has been associated with an increase in hate crimes offline (Hatzipanagos, 2018; Laub, 2019; Relia et al., 2019); therefore, the ability to successfully tackle this issue within the virtual space itself is vital. Sexism refers to a sub-classification of hate speech where the targeted people are typically female. Women are more likely to report having experienced sexual harassment online (16% vs. 5%) or being cyber-stalked (13% vs. 9%) compared to men (Vogels, 2021); with 1 in 10 women reporting having experienced cyber harassment since the age of 15 in the European Union (UN Women, 2020). Women and girls are specifically seen to face a digital gender divide1, especially with the COVID-19 pandemic being the first major one in the age of social media2. While social media platforms like Twitter do ban hate speech3, these policies are enforced primarily through manual methods which cannot scale up to counteract the data being produced (Waseem and Hovy, 2016; Zhang and Luo, 2019). Hence, more automatic methods are essential to successfully tackle this problem. This paper looks at creating and improving neural network models to perform binary and multiclass sexism classification using the dataset provided for the first shared task on sEXism Identification in Social neTworks (EXIST) at IberLEF 2021 (RodriÃÂguez-SaÃÂnchez et al., 2021). In this paper, sexism refers to hate speech against women specifically, with the dataset consisting of texts obtained from Twitter and Gab. This paper presents a variety of models including Long-Short-Term Memory networks (LSTMs), Bidirectional Long-Short-Term Memory networks (Bi-LSTMs), and Convolutional Neural Networks (CNNs) tested against this dataset, with the best performance for both tasks seen with a model utilising Bidirectional Encoder Representations from Transformers (BERT) contextual embeddings in conjunction with a CNN containing three filter sizes of 4, 6, and 8. Data augmentation is also seen to improve the modelÃ¢ÂÂs performance for the multi-class classification task. The performance metrics are reported for each model with a discussion of the errors presented to explore the difficulty in classifying a subjective topic like sexism in natural language texts. The rest ofpaper is organised as follows. In Section 2, related work in the field of hate speech and sexism classification are looked at, Section 3 talks about the dataset used for the experiments, Section 4 talks about system architecture and details the models used in this paper, Section 5 presents and discusses the results, Section 6 talks about error analysis and Section 7 concludes the paper. RELATED WORK Research has been conducted regarding hate speech on various social media platforms like Twitter (Davidson et al., 2017; Shushkevich and Cardiff, 2018; RodriÃÂguez-SaÃÂnchez et al., 2020), Facebook, (Vigna et al., 2017; Raiyani et al., 2018; Mandl et al., 2019) and Reddit (Qian et al., 2019). Initial research regarding classifying hate speech was feature based, with approaches based on bag-of-words (BoW), character- level, and word-level n-grams (Kwok and Wang, 2013; Mehdad and Tetreault, 2016; Waseem and Hovy, 2016). Then, traditional machine learning methods like support vector machines (SVM) and logistic regression were used. One of the first uses of machine learning to detect offensive tweets was presented by Xiang et al. (2012) where logistic regression was used as opposed to the utilisation of pattern- based approaches (Gianfortoni et al., 2011; Mondal et al., 2017). One of the first instances of using neural networks and word embeddings to tackle hate speech classification was done by Djuric et al. (2015) where a continuous BoW model was used to learn paragraph2vec embeddings, with these embeddings then used to train a binary classifier. For the 2018 IberEval Automatic Misogyny Identification (AMI) tasks, which required classification of English and Spanish or English and Italian tweets, the majority of the participants utilised SVMs and Ensemble of Classifiers (EoC) (Ahluwalia et al., 2018; Fersini et al., 2018; Pamungkas et al., 2018; Shushkevich and Cardiff, 2018). Good results were also seen through the usage of Bi-LSTMs and Conditional Random Fields (CRFs) on the same task (Goenaga et al., 2018). An alternative architecture was proposed by Zhang and Luo (2019) with two deep neural network models to tackle hate speech classification on Twitter datasets. These models consist of CNN and Gated Recurrent Unit (GRU) architectures with the results outperforming the best methods at the time. More recently, the introduction of BERT has led to new state-of-the-art performances across a range of natural language processing tasks, including text classification (Devlin et al., 2018). BERT is a multi-layer bidirectional transformer encoder which notably uses bidirectional self- attention to learn contextual information between words and sub-words within a text (Alammar, 2018). BERT has been pre-trained using BooksCorpus (800M words) and English Wikipedia (2500M words) on masked language modelling and next sentence prediction (Devlin et al., 2018). This causes the embeddings taken from the model to contain useful contextual information that can be fine-tuned for specific tasks. RodriÃÂguez-SaÃÂnchez et al. (2020) show BERT being used to give the best performance on the task of identifying sexist content through fine tuning pre-trained mBERT-Base parameters with a fully connected layer. Multi-label sexism classification was first seen in a paper by Parikh et al. (2020) where a BERT based neural architecture was used along with distributional and word level embeddings. Samghabadi et al. (2020) also show BERT being used without fine-tuning to identify aggression and misogyny in English, Hindi, and Bengali tweets with positive results from the model. Limited research has been conducted on the automatic classification of subtle expressions of sexism encompassing a broad range of categories, compared to the sole use of profanities or explicit hatred against women. RodriÃÂguez- SaÃÂnchez et al. (2020) collected instances of various types of sexism, ranging from subtle inequality to explicit violence to create a dataset to then be used in an automatic classification task. The range of expressions collated is similar to the dataset used in this paper. An important point to note is that hate speech and sexism is defined differently across these papers, with offensive language often considered to be equivalent (Davidson et al., 2017). Another challenge forsexism classification is the lack of an established benchmark dataset. Detecting sexist expressions is a challenge for human coders as well, with racist or homophobic tweets often considered to be hate speech while sexist or derogatory terms are found to be offensive as opposed to hateful (Waseem and Hovy, 2016; Zhang and Luo, 2019). Hence, more automatic methods are essential to successfully tackle this problem. This paper looks at creating and improving neural network models to perform binary and multiclass sexism classification using the dataset provided for the first shared task on sEXism Identification in Social neTworks (EXIST) at IberLEF 2021 (RodriÃÂguez-SaÃÂnchez et al., 2021). In this paper, sexism refers to hate speech against women specifically, with the dataset consisting of texts obtained from Twitter and Gab. This paper presents a variety of models including Long-Short-Term Memory networks (LSTMs), Bidirectional Long-Short-Term Memory networks (Bi-LSTMs), and Convolutional Neural Networks (CNNs) tested against this dataset, with the best performance for both tasks seen with a model utilising Bidirectional Encoder Representations from Transformers (BERT) contextual embeddings in conjunction with a CNN containing three filter sizes of 4, 6, and 8. Data augmentation is also seen to improve the modelÃ¢ÂÂs performance for the multi-class classification task. The performance metrics are reported for each model with a discussion of the errors presented to explore the difficulty in classifying a subjective topic like sexism in natural language texts. The rest of this paper is organised as follows. In Section 2, related work in the field of hate speech and sexism classification are looked at, Section 3 talks about the dataset used for the experiments, Section 4 talks about system architecture and details the models used in this paper, Section 5 presents and discusses the results, Section 6 talks about error analysis and Section 7 concludes the paper. RELATED WORK Research has been conducted regarding hate speech on various social media platforms like Twitter (Davidson et al., 2017; Shushkevich and Cardiff, 2018; RodriÃÂguez-SaÃÂnchez et al., 2020), Facebook, (Vigna et al., 2017; Raiyani et al., 2018; Mandl et al., 2019) and Reddit (Qian et al., 2019). Initial research regarding classifying hate speech was feature based, with approaches based on bag-of-words (BoW), character- level, and word-level n-grams (Kwok and Wang, 2013; Mehdad and Tetreault, 2016; Waseem and Hovy, 2016). Then, traditional machine learning methods like support vector machines (SVM) and logistic regression were used. One of the first uses of machine learning to detect offensive tweets was presented by Xiang et al. (2012) where logistic regression was used as opposed to the utilisation of pattern- based approaches (Gianfortoni et al., 2011; Mondal et al., 2017). One of the first instances of using neural networks and word embeddings to tackle hate speech classification was done by Djuric et al. (2015) where a continuous BoW model was used to learn paragraph2vec embeddings, with these embeddings then used to train a binary classifier. For the 2018 IberEval Automatic Misogyny Identification (AMI) tasks, which required classification of English and Spanish or English and Italian tweets, the majority of the participants utilised SVMs and Ensemble of Classifiers (EoC) (Ahluwalia et al., 2018; Fersini et al., 2018; Pamungkas et al., 2018; Shushkevich and Cardiff, 2018). Good results were also seen through the usage of Bi-LSTMs and Conditional Random Fields (CRFs) on the same task (Goenaga et al., 2018).