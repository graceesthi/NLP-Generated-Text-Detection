Abstract Machine translation (MT) system aims to translate source language into target language. Recent studies on MT systems mainly focus on neural machine translation (NMT). One fac- tor that significantly affects the performance of NMT is the availability of high-quality paral- lel corpora. However, high-quality parallel cor- pora concerning Korean are relatively scarce compared to those associated with other high- resource languages, such as German or Italian. To address this problem, AI Hub recently re- leased seven types of parallel corpora for Ko- rean. In this study, we conduct an in-depth ver- ification of the quality of corresponding par- allel corpora through Linguistic Inquiry and Word Count (LIWC) and several relevant ex- periments. LIWC is a word-counting software program that can analyze corpora in multiple ways and extract linguistic features as a dictio- nary base. To the best of our knowledge, this study is the first to use LIWC to analyze par- allel corpora in the field of NMT. Our find- ings suggest the direction of further research toward obtaining the improved quality paral- lel corpora through our correlation analysis in LIWC and NMT performance. Introduction In recent years, the demand for machine translation (MT) systems has been continuously increasing and its importance is growing, especially for the industrial services. (Vieira et al., 2021; Zheng et al., 2019) Companies, such as Google, Facebook, Mi- crosoft, Amazon, and Unbabel continue to conduct research and formulate plans to commercialize ap- plications related to MT. From the late 1950s, numerous MT-related projects were proceeded by mainly focusing on rule-based and statistical-based approaches before the advent of deep learning technology. As deep learning based neural machine translation (NMT) was proposed and adopted to several researches, it has been gradually figured out that more supe- rior performance can be derived through NMT ap- proach (Bahdanau et al., 2014; Vaswani et al., 2017;Lample and Conneau, 2019; Song et al., 2019). Followed by the adoption of deep learning based technique, the improvements of computing power (e.g. GPU) and corresponding enhancement of par- allel processing accelerated the advancement of NMT. Recently, release of open source frameworks, such as Pytorch(Paszke et al., 2019), and lowered accessibility to the big data further facilitated vig- orous and diverse research. However, several issues considering the enhance- ment of the NMT system remain still. Represen- tatively, limitations in ensuring the quality of data is an unresolved issue. As have previously been studied, the quality of the training data is deeply related to the NMT performance (Park et al., 2020d, 2021b). The major problem is that the process of building a high-quality parallel corpus is time- consuming and expensive, and it is significantly difficult for low-resource languages, such as Ko- rean. Although data-augmentation techniques, such as back translation (Edunov et al., 2018) and copied translation (Currey et al., 2017) have been intro- duced, as the human supervision is generally mini- mized or excluded in the data generation process, the quality of such pseudo-generated parallel cor- pus cannot be guaranteed (Burlot and Yvon, 2019; Epaliyana et al., 2021). This restricted the usage of pseudo-generated parallel to complements of human-labeled gold parallel corpus, rather than its substitutes (Imankulova et al., 2017). For the alleviation of above limitations, numer- ous studies on the collection of high-quality train- ing data have been conducted, such as parallel cor- pus filtering (PCF) research and Data Dam project. PCF refers to a research field that aims to filter out low-quality noisy data (i.e. sentence pairs) residing in the parallel corpus, and improve the over- all quality of the corpus. PCF is currently being applied to various NMT studies and contributed to the advancement of the NMT systems (Koehn et al., 2019; Park et al., 2020c). While the amount of training data caused significant impact on the statistical-based MT approaches, the quality of data is treated as more important than the amount of data in general deep learning-based MT approaches (Khayrallah and Koehn, 2018; Koehn et al., 2020b). Moreover, Data Dam 1 projectsbuilding high- quality parallel corpora nationally are in progress. In the Republic of Korea, a large number of paral- lel corpora is open to the public through AI-Hub 2, which is organized by the National Information Society Agency (NIA) (Park and Lim, 2020). Following these research trends, where the qual- ity is treated more importantly than the quantity in the process, we analyzed the above Korean-English parallel corpus distributed by AI-Hub. Despite its sufficient amount of data, the quality of corresponding corpus has not been confirmed clearly. This may restrict the uncon- strained utilization of such corpus in adoption to the NMT model, as low quality data may degrade the overall performance. In this study, we conducted several quality verification experiments including Linguistic Inquiry and Word Count (LIWC) (Pen- nebaker et al., 2001; Tausczik and Pennebaker, 2010), and clarified the quality and characteris- tics of such corpus. By analyzing various factors that can affect NMT performance, we proposed a method that can be applied in future research using the analysis results. LIWC is a text-analysis tool that automatically analyzes the number of words in a sentence and classifies words with similar meanings and sen- timental characteristics. LIWC extracts various interpersonal variables related to clinical, social, physiological, cognitive, psychological, and de- velopmental contexts that cannot be detected us- ing previous text-analysis programs. Additionally, LIWC comprises a variety of features for analyzing text. LIWC generally used to recognize linguistic markers for mental health study in Psychopathol- ogy such as detecting Narcissism(Holtzman et al., 2019), schizophrenia(Bae et al., 2021), bipolar dis- order(Sekulic ÃÂ et al., 2018). However, LIWC pro- vides various linguistic features, word count, gender bias and so on, so it can be used for various analyses. In this study, we use LIWC to analyze parallel corpora based on diverse properties. It is also first time to analyze corpus using LIWC. In addition, we conduct baseline translation ex- periments by training transformer-base model struc- ture (Vaswani et al., 2017) through all the parallel corpora given by AIhub. By analyzing MT per- formance of corresponding models, we propose further research directions on MT for the Korean language. The contributions of this study are as follows: For the first time, we conduct a deep data anal- ysis on AI-Hub data. To the best of our knowl- edge, this is the first time LIWC has been used to analyze corpora. This study acts as a mile- stone for further studies on NMT with respect to the Korean language. We conduct baseline translation experiments on all the data in the AI-Hub parallel corpus. Our experiments provide a foundation for fur- ther research on Korean-based NMT. We discovered that many factors might cause decreasing model performance, and we pro- vide the direction that those factors could be filtered through our correlation analysis be- tween LIWC and model performance. Conclusions In this work, we proceeded with a quality eval- uation of all the Korean-related parallel corpus, released by AI Hub. For the model-centric perfor- mance validation, we constructed a transformer based NMT model trained with each parallel cor- pus. Through quantitative and qualitative analysis of these NMT models, we point out some proba- ble limitations on constructing corpora. First, for learning NMT model well in specific field, the do- main corpora should contain various words and expressions in consideration of the excessive per- formance difference between domain and general corpora. Second, given the significant performance gap in terms of language direction, half of the paral- lel data to be built must be configured in the source language and the other half in the target language and then translated respectively. Away from the model-centric analysis, we en- couraged data-centric research through LIWC anal- ysis. We figured out the association between LIWC and model performance in terms of data filtering. Through this analysis, we suggested the direction of further work to improve model performance. The national level re-examination of the various standards and building processes should be made for the encouragement of AI data construction re- searches. In the future, we plan to investigate ef- ficient beam search strategies and new decoding methods by utilizing these AI Hub data. Also, to more accurately measure the model performance, we plan to build an official Korean-English test set.