Abstract Natural Language Processing (NLP) is a branch of artificial intelli- gence that gives machines the ability to decode human languages. Part- of-speech tagging (POS tagging) is a pre-processing task that requires an annotated corpus. Rule-based and stochastic methods showed remarkable results for POS tag prediction. On this work, I performed a mathematical model based on Hidden Markov structures and I obtained a high-level ac- curacy of ingredients extracted from text recipe with performances greater than what traditional methods could make without unknown words con- sideration. Introduction Artificial intelligence had shown a great progress in the recent years especially the deep learning branch where learning techniques have been improved very quickly. The combination of representation learning and deep learning have allowed the emerging of a new AI class called deep reinforcement learning. Deep Reinforcement learning tend to estimate value functions from exper- iments and simulations and using dynamic programming through Deep Re- inforcement learning is an efficient way to build reactive strategies acting on instantaneous control. An algorithm which approves its performance by experi- ence is an algorithm capable of avoiding his own mistakes through a combination of a strong memory fed by fresh helpful data and the ability to keep winning pre- dictions after a long-term performance (Barto, Bradtke, & Singh, 1995) (Mnih et al., 2015). Neural Network can be considered as a dynamic Reinforcement Learning scheme where the layers are putted in a parallel way to have a cascaded trans- mission of the treated signal (Fukushima & Miyake, 1982) (LeCun et al., 1989) and where a prior knowledge is important to predict the output state of new observations. Sequential modeling is a way to process data in natural language processing by maximizing awards after manipulating situation and producing resulting actions (Vithayathil Varghese & Mahmoud, 2020) (LeCun, Bengio, & Hinton, 2015). A sequential model representation is influenced by its data representation and how tensors are trained to produce an optimal control (Bengio, Courville, & Vincent, 2013) To improve the target learning task, transfer learning is used as a powerful technique to increase the value of the most probable cases inside a state matrix (Boutsioukis, Partalas, & Vlahavas, 2011). Transferring the knowledge helps us to reduce the amount of data consumed and rely on feature engineering to reduce the noise caused by annotation errors and other tag-set anomalies in a context of multi-agent system. Extracting ingredients automatically from a recipe text is an extremely use- ful activity especially when we want to analyze a massive data of text recipes. Rule-Based methods were implemented to extract information from unstruc- tured recipe data (Silva, Ribeiro, & Ferreira, 2019) Ingredients is not the only useful information we want to extract; in this work we are going to use Hidden Markov Models especially Viterbi algorithm with some modification to make it receiving two unique features: POS-tags and tokens, to predict ingredient states. Previous works Many previous works were interested in analyzing cuisine recipes, for exam- ple Sina Sajadmanesh (Sajadmanesh et al., 2017) presented an analysis of the ingredients diversity around the word using an ingredient-based classifier to dif- ferentiate between recipes around the word based on its geographical identity. Sina Sajadmanesh (Sajadmanesh et al., 2017) studied the diversity of ingredi- ents in dishes with introduction of global diversity (the ability to have diversified ingredients between recipes) and local diversity (the ability to have diversified ingredients within a recipe). Other related work for culinary habits is Yong-Yeol Ahn paper (Ahn, Ahnert, Bagrow, & Barab ́asi, 2011) who introduced the notion of Flavor Network and tried to verify the Food Paring hypothesis introduced on the 90’s by Heston Blumenthal and Francois Benzi. Flavor network as described by Ahn is a graph where the nodes are the ingredients extracted from recipes and weights are shared flavors between nodes. Food paring hypothesis is an indicator calculated after forming the Flavor Network to show if in a country or in a geographical part of the word we have tasty recipes or the ingredients do not have similar molecules. Tiago Simas (Simas, Ficek, Diaz-Guilera, Obrador, & Rodriguez, 2017) introduced the notion of food bridging formed with semi-metric distances. A group of scientists in a recent publication (Van Erp et al., 2021) devel- oped a state of the art of the use of artificial intelligence and natural language processing in analyzing food recipes. In this article we can found collected ref- erences talking about the challenging part in collecting food and recipe data. For example, Ahnert (Ahnert, 2013) presented the emergence of computational gastronomy in food science and its effect on culinary practices. Aiello and al (Aiello, Schifanella, Quercia, & Del Prete, 2019) discovered what are the most important predictors in food responsible of three diseases in a population sit- uated in London. (Amato & Cozzolino, 2020) extracted ingredients from food text to alert readers from allergens presence in a recipe. I agree with (Van Erp et al., 2021) concerning how challenging to use IA in food domain and how it will resolve issues concerning the creation of a data driven analysis of nutrition. In our paper data extracted can be used in a phone application or a recommended system for people who want to take care of their health. All previously cited researches on cuisine recipes need information extrac- tion from text recipe to use it on graphical visualization and statistical analysis. Information extraction can be used manually by extracting ingredients indi- cated on recipes or automatically. The problem in automatic extraction is that information should be precise to have also precise analysis, for example some ingredients take only one word and others can take two or three words. Another problem on automatic information extraction is that some ingredients that take one word have in common some words with other ingredients that have more than one word which make automatic information extraction more difficult. I tried to develop a mathematical model dedicated to extract ingredients from text recipe written in Arabic language with precision higher than what tradi- tional methods could make. According to Cutting (Cutting, Kupiec, Pedersen, & Sibun, 1992), a Tagger must be robust that should deal with unknown words, efficient that can deal with large corpora, accurate that can tag with high accu- racy, tunable that can deal with different corpora and reusable that take small efforts to re-target a new corpus. There are three types of POS Tagger: Taggers based on stochastic models, Taggers based on rules and Taggers Based on neural networks. On this work we will use Taggers based on HMM models. The use of POS tags as external features to solve NER problems was experimented by Zhou (Zhou & Su, 2002) but it was discarded because it showed bad results but our methodology and experiments demonstrate that using POS tags as external features is not a bad idea. This could be explained by the difference between our tokens and Zhou’s tokens: tokens as defined by Zhou is a pair of word-feature and in our model, token is only a word from our corpus. Conclusion Our Ingredient Extractor algorithm showed great results. It is based on HMM methods. We realized it by training two layers: first we trained tokens by tagging POS tags and second, we trained tokens by extracting the ingredients. Our HMM model needed modifications in iteration step because we didn’t get a square transition probability matrix or a square lexical probability matrix after the training step. A detailed iterations of our method is illustrated in appendix A. We can ameliorate our model by calculating the probabilities in it differently not as simple as we deed. We can make our model more interesting by adding two layers, one for extracting quantities and the other for extracting unities.