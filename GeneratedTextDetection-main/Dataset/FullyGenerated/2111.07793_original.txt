Abstract Developing speech technologies is a challenge for low-resource lan- guages for which both annotated and raw speech data is sparse. Maltese is one such language. Recent years have seen an increased interest in the computational processing of Maltese, including speech technologies, but resources for the latter remain sparse. In this paper, we consider data augmentation techniques for improving speech recognition for such lan- guages, focusing on Maltese as a test case. We consider three different types of data augmentation: unsupervised training, multilingual training and the use of synthesized speech as training data. The goal is to de- termine which of these techniques, or combination of them, is the most effective to improve speech recognition for languages where the starting point is a small corpus of approximately 7 hours of transcribed speech. Our results show that combining the three data augmentation techniques studied here lead us to an absolute WER improvement of 15% without the use of a language model. Keywords Data Augmentation; Speech Recognition; Maltese Language; Unsupervised Transcriptions; Multilingual Training; Synthesized Speech Introduction In recent years, the field of Natural Language Processing has seen renewed in- terest in multilingual models. New techniques of transfer and multi-task learn- ing, as well as the availability of multilingual datasets, have motivated the de- velopment of large-scale reusable models (Devlin et al., 2019; Conneau et al., 2020) and NLP benchmarks (e.g. Hu et al., 2020; Liang et al., 2020). Many of these models rely on large quantities of data for pretraining. As a result, ‘under-resourced’ languages, for which such data is less easy to come by, remain under-represented in these developments. To take an example, the large-scale language models currently in use in many language understanding tasks, such as Multilingual BERT (Devlin et al., 2019) or XLM-R (Conneau et al., 2020) are pretrained on multilingual data available in online resources such as Wikipedia or CommonCrawl (Wenzek et al., 2020). This, however, also means that lan- guages with small speaker populations, which also tend to be under-represented on the web, are not represented in these models. Similar developments are being seen in Automatic Speech Recognition (ASR) (Baevski et al., 2020a). There has been a lot of work focused on transfer learning-based improvements to speech recognition systems in order to make many modern architectures accessible to a wider set of languages. This has taken a number of different forms. For example Wang et al. (2020) use high-to- low resource language machine translation as an intermediate task to create a language model for a low-resource target language. More in line with parallel developments in NLP, recent research has also turned towards large, multilin- gual, pretrained ASR architectures. For example, Pratap et al. (2020) show that great benefits for low-resource speech recognition can accrue from a multilingual acoustic model. However, the majority of languages used in this work have over 100 hours of training data available. A different line of research has been pur- sued in Wav2Vec2 (Baevski et al., 2020b), which builds on the earlier Wav2Vec model Schneider et al. (2019). This architecture can learn robust speech repre- sentations of sufficient quality to perform recognition even for target languages with a very low volume of labelled data (in the order of one hour), reaching the same performance as previous state-of-the-art systems requiring 100 times more data (100 hours). Wav2Vec2 can also provide good results with just ten minutes of labelled speech data, reaching word error rates as low as 4.8, given substantial pretraining on 53,000 hours of unlabelled data. This work therefore demonstrates that semi- or self-supervised pretraining, similar in spirit to what we have seen in recent years with language models in NLP, can result in ro- bust representations that lower the requirements on labelled data. Once again, however, the key is in ensuring that sufficient data is available for pretraining, in this case in the form of audio. Indeed, Baevski et al. (2020b) describe two settings, one with 960 hours of unlabelled data, and another with 60,000 hours. In summary, research in NLP in both the textual and speech modalities has convincingly shown the benefits of pretraining with minimal supervision. Yet, from the perspective of under-resourced languages with low presence on the web, in the form of either text or speech, their feasibility is far from guar- anteed. Maltese provides a good example of this kind of scenario. Web-scale textual or speech data is harder to obtain for Maltese compared to languages such as English or Mandarin and we expect that similar challenges arise for many other under-resourced languages (Besacier et al., 2014). Furthermore, as recent critiques of large-scale pretraining approaches have emphasised, even where web-scale data is available, there are significant risks arising from its ‘unfathomable’ nature, not least that it is likely to be extremely noisy, while not guaranteeing representativeness across demographic or ethnic groups, and/or across language varieties Bender et al. (2021); Rogers (2021). Lastly, the com- putational resources needed for such experiments are not available to all research teams. Given these challenges, this paper presents an exploratory analysis of a set of related techniques for improving ASR for Maltese using different data augmen- tation strategies, relying on the use of smaller, curated datasets in the target language, the use of larger datasets in related languages, and the contribution of artificial data augmentation. Briefly, the scenario in which these experiments were designed consists of the following: Approximately7hoursoflabelledspeechdatainthetargetlanguage(here: Maltese); A small amount of unlabelled speech data in the target language; A medium sized corpus of Maltese text (250m tokens); A concatenative speech synthesis system whose output, while not of high quality, can be exploited for data augmentation purposes; Substantial data in a number of other languages – notably Arabic, Italian and English – which are typologically and historically related to Maltese. In the remainder of this section, we first introduce some salient features of the Maltese language itself, followed by an explanation of the motivation for these experiments. The section concludes with an outline of the rest of the paper. Maltese and other languages Maltese is spoken as a first language by just under half a million citizens of the Maltese islands (Mena et al., 2020); it is also taught as a second language in a few countries. It is the national language of Malta, but co-exists with two other official languages (English and Maltese Sign Language). In recent years, there has been significant gain in digital support for the Maltese language. A large (250m tokens) annotated text corpus is available, as are tools for segmentation and morphosyntactic labelling (Gatt and Cˇ ́eplo ̈, 2013) and electronic lexical repositories (Camilleri, 2013).1 In addition, some studies have focused on natural language analysis tasks such as morphologi- cal labelling (Borg and Gatt, 2017; Ravishankar et al., 2017) and dependency parsing (Tiedemann and van der Plas, 2016; Zammit, 2018). Despite these advances, Maltese remains under-resourced on a number of fronts, especially where speech is concerned. Concatenative speech synthesis systems have been developed using classical (e.g. diphone synthesis) methods (Micallef, 1997; Borg et al., 2011), but there are currently no tools for ASR, except for some preliminary experiments done by Mena et al. (2020). The most important reason for this is a lack of resources. In the absence of large reposito- ries of paired speech and text samples, it is not realistic to use current end-to-end methods for speech recognition. As argued above, it is also hard to obtain large samples of unlabelled speech for pretraining purposes. The present paper focuses on a variety of approaches designed to overcome this bottleneck, conducted in the context of the project MASRI - Maltese Auto- matic Speech Recognition2. Starting from a relatively small dataset of Maltese text and speech, we describe experiments deploying a variety of techniques for data augmentation. The broad question we address is therefore the following: Given an under-resourced language for which a relatively small speech-to-text dataset is available, what data augmentation methods work best to bring ASR performance to a level which provides a suitable, competitive baseline for future development? In our experiments, we maintain a focus on data augmentation for end-to- end ASR. While our focus is on the Maltese language, the findings presented here are of relevance to speech technology researchers working on other under- resourced languages. While a variety of data augmentation methods can be envisaged, our focus on Maltese makes two lines of inquiry particularly relevant. Here, we give an outline of the motivation for each one. Typological relatedness Maltese bears strong historical relationships to three major languages. From a historical perspective, it has been characterised as having a Semitic/Arabic stratum, a Romance (Italian/Sicilian) superstratum, and an English adstratum (Brincat, 2011). This characterisation reflects the his- torical development of Maltese, originally a variety of Arabic, which came into intensive contact with Italian due to its geographical proximity and historical relations with that country. This was followed by a period of intensive contact with English (Malta was a British colony from 1800 to 1964), as a result of which, the Maltese population is largely bilingual. The impact of this linguistic history is clearly evident in the language at many levels of analysis, including the lexical and morphological (Borg and Gatt, 2017). From the perspective of the present experiments, this suggests that a promising way to approach the data augmentation problem is to exploit the (much larger) resources available for these languages. We do this by transcribing speech data from one of these languages with a baseline Maltese acoustic model trained on a very small corpus (Section 5.2); and using a ‘language mixture’ approach (Section 5.3), in which an end-to-end system is pretrained on data using mixtures of such languages. In both cases, pretraining is followed by a fine-tuning step. Synthesis Given the existence of a concatenative speech synthesis system for Maltese, we also discuss data augmentation experiments involving artificially synthesised training data (Section 5.4). Outline of the paper The rest of this paper is structured as follows. Section 2 reviews data augmen- tation methods, especially for speech. In Section 3 we describe the datasets we use whilst Section 4 describes the experimental methodology. Section 5 presents a variety of experiments and results, in which we aim to identify the best data augmentation methods for ASR in Maltese. Section 6 concludes with a general discussion and some pointers to future work. Conclusions and future work The work presented in this paper had one over-arching theme - the analysis of whether ASR performance for under-resourced languages can be improved by various data augmentation methods. We elicited a detailed taxonomy of what types of augmentation exist in the literature, and we also devised a consistent set of experiments that sift through the many possibilities, whilst providing clear results for each. The results obtained are specific to ASR for the Maltese language, but we postulate that similar approaches would yield similar improve- ments for other under-resourced languages. In order to assess that we were indeed testing for improvements in acoustic modelling based on data augmentation, this work specifically makes no use of language modelling as part of the ASR pipeline. We do however show that language model rescoring does indeed have a big effect on WER (section 4.6), and in future experimentation, we intend to combine the best methods from this work with further language modelling experiments to obtain state-of-the- art performance for Maltese ASR. That is however, a different research question altogether. As part of our efforts in maintaining consistency in our experiments, ques- tions were also raised as to whether augmentation is helpful for pretraining methodologies, whilst keeping the network architectures unchanged. To this end we employ training cycles, and show that some measure of performance improvement is obtained, as shown in Section 5.2. We also postulate that this approach is generic enough to be proposed for any ASR setup for an under- resourced target language. The one aspect of the work we present here that is probably dependent on the target language is in section 5.3. The ancillary language data chosen is not random. This augmentation is based on languages which are somehow related to Maltese - either historically, culturally or linguistically. The results show that supervised transcriptions of some closely related languages provide a substantial improvement in WER (Section 5.3.1). The choice of these languages, however, has to be assessed individually based on the target language. Furthermore, this paper then analyzed the use of synthesized speech for ASR training (Section 5.4). Whilst data from a speech synthesis system might not always be readily available for under-resourced languages, we highlight the fact that the synthetic speech quality need not be of very good quality for immediate benefits in WER. In fact, the synthesis system used is produces highly unnatural speech with many pronunciation errors, yet we gained the largest improvements from using this method of data augmentation. In summary, the conclusions we can draw from the work presented is as follows: Both gold and noisy transcriptions can be used as data augmentation techniques, up until a limit is reached after various training cycles. Noisy transcriptions have poorer performance with respect to gold tran- scriptions. In the absence of sufficient gold transcription quantities, how- ever, the utilization of noisy transcriptions of the target language shows substantial improvements in WER. Mixing pretraining data from non-target languages is useful, especially with a small data batch from the target language. There are however limits to this and adding more data beyond a certain point yields diminishing returns. The use of synthesized speech in the target language, as training data, outperforms the use of gold or noisy transcriptions in languages different to the target, even when the synthesized speech has a low quality. The results we obtain from this work are very encouraging, as we have ob- served an absolute reduction of 15% in WER from our baseline systems (63.71% WER) to the system resulting from the best setup based on pretraining and fine tuning from an augmented dataset (48.97% WER). This is a remarkable improvement in light of the fact that they revolve around a curated Maltese ASR corpus of less than 7 hours of speech. We believe this work sets a starting point for all future work in ASR for the Maltese language, and propose that all languages which are similarly under- resourced could follow the methodology we outline in this paper to assess and capitalize on data augmentation methods. A promising direction for future work is to explore the augmentation tech- niques presented here with a different neural architecture. Recent research in multilingual NKP has showing the remarkable performance of models in the Transformer paradigm (Vaswani et al., 2017), both for textual, language- understanding tasks with models such as multilingual BERT (Devlin et al., 2019) and XLM-R (Conneau et al., 2020) and for speech recognition with Wav2Vec- 2 Baevski et al. (2020b). These approaches provide impetus for further experi- mentation, with a view to identifying the best strategies for data augmentation to make ASR more feasible for low-resource languages.