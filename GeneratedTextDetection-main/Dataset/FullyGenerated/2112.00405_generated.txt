Abstract Named entity recognition (NER) models gen- erally perform poorly when large training datasets are unavailable for low-resource do- mains. Recently, pre-training a large-scale language model has become a promising di- rection for coping with the data scarcity is- sue. However, the underlying discrepancies between the language modeling and NER task could limit the modelsÃ¢ÂÂ performance, and pre- training for the NER task has rarely been stud- ied since the collected NER datasets are gen- erally small or large but with low quality. In this paper, we construct a massive NER cor- pus with a relatively high quality, and we pre- train a NER-BERT model based on the cre- ated dataset. Experimental results show that our pre-trained model can significantly outper- form BERT (Devlin et al., 2019) as well as other strong baselines in low-resource scenar- ios across nine diverse domains. Moreover, a visualization of entity representations further indicates the effectiveness of NER-BERT for categorizing a variety of entities. 1 Introduction Named entity recognition1 (NER) plays an im- portant role in information extraction and text processing. Current NER systems heavily rely on large training datasets to achieve good perfor- mance (Lample et al., 2016; Chiu and Nichols, 2016; Ma and Hovy, 2016; Yadav and Bethard, 2018; Li et al., 2020), and a well-designed NER model normally has a poor generalization ability on low-resource domains, where large numbers of training data are unavailable (Jia et al., 2019; Liu et al., 2021b). Given that collecting numer- ous NER training data is not just expensive but also time-consuming, it is essential to construct a NER model that can quickly adapt to low-resource domains using only a few data examples. Recently, pre-training a large-scale language model (Devlin et al., 2019; Liu et al., 2019) has been shown to be effective in a data scarcity sce- nario (Ma et al., 2019; Radford et al., 2019; Chen et al., 2020). However, the underlying discrepan- cies between the language modeling and the NER task could limit the performance of pre-trained lan- guage models on this task. Unfortunately, conduct- ing a NER-specific pre-training has rarely been studied because constructing a large-scale and high- quality corpus for this purpose is not a simple task. Although there are plenty of publicly available NER datasets, they generally have different an- notation schemes and different entity categories. For example, the CoNLL2003 dataset (Sang and De Meulder, 2003) has the Ã¢ÂÂmiscellaneousÃ¢ÂÂ entity category, which the Broad Twitter dataset (Der- czynski et al., 2016) lacks, and the WNUT2017 dataset (Derczynski et al., 2017) has Ã¢ÂÂcorporationÃ¢ÂÂ and Ã¢ÂÂgroupÃ¢ÂÂ entity categories, while many other datasets (Sang and De Meulder, 2003; Lu et al., 2018) use the Ã¢ÂÂorganizationÃ¢ÂÂ entity type. Thus, it is difficult to unify the annotation scheme for all datasets, and jointly training models on different schemes will confuse the model in categorizing entities. In addition, the existing NER datasets are much smaller than those of the plain text used for the language modeling task, which will result in a less effective pre-training. Instead of utilizing manually annotated NER datasets, a few previous studies (Cao et al., 2019; Mengge et al., 2020) have focused on leverag- ing weakly-labeled NER data constructed from Wikipedia to enhance the modelÃ¢ÂÂs performance. Cao et al. (2019) generated the weakly-labeled data based on Wikipedia anchors and a taxonomy, but the quality of the produced data is relatively low and the number of entity categories is limited. To cope with these issues, Mengge et al. (2020) lever- aged a gazetteer to obtain coarse-grained entities and k-means clustering to further mine the fine-grained entities. However, obtaining fine-grained labels based on clustering algorithms is not stable, which could limit the effectiveness of pre-training. In this work, we first aim to construct a large- scale NER dataset with a relatively high quality and abundant entity categories. After that, our goal is to prove that using the created dataset to pre-train an entitymodel can outperform pre-trained language models on the low-resource NER task. Similar to Cao et al. (2019), we build the NER dataset based on the Wikipedia corpus. To improve the quality and increase the number of entity cate- gories, we utilize the DBpedia Ontology (Mendes et al., 2012) to assist in categorizing a variety of entities. 1 Introduction Named entity recognition1 (NER) plays an im- portant role in information extraction and text processing. Current NER systems heavily rely on large training datasets to achieve good perfor- mance (Lample et al., 2016; Chiu and Nichols, 2016; Ma and Hovy, 2016; Yadav and Bethard, 2018; Li et al., 2020), and a well-designed NER model normally has a poor generalization ability on low-resource domains, where large numbers of training data are unavailable (Jia et al., 2019; Liu et al., 2021b). Given that collecting numer- ous NER training data is not just expensive but also time-consuming, it is essential to construct a NER model that can quickly adapt to low-resource domains using only a few data examples. Recently, pre-training a large-scale language model (Devlin et al., 2019; Liu et al., 2019) has been shown to be effective in a data scarcity sce- nario (Ma et al., 2019; Radford et al., 2019; Chen et al., 2020). However, the underlying discrepan- cies between the language modeling and the NER task could limit the performance of pre-trained lan- guage models on this task. Unfortunately, conduct- ing a NER-specific pre-training has rarely been studied because constructing a large-scale and high- quality corpus for this purpose is not a simple task. Although there are plenty of publicly available NER datasets, they generally have different an- notation schemes and different entity categories. For example, the CoNLL2003 dataset (Sang and De Meulder, 2003) has the Ã¢ÂÂmiscellaneousÃ¢ÂÂ entity category, which the Broad Twitter dataset (Der- czynski et al., 2016) lacks, and the WNUT2017 dataset (Derczynski et al., 2017) has Ã¢ÂÂcorporationÃ¢ÂÂ and Ã¢ÂÂgroupÃ¢ÂÂ entity categories, while many other datasets (Sang and De Meulder, 2003; Lu et al., 2018) use the Ã¢ÂÂorganizationÃ¢ÂÂ entity type. Thus, it is difficult to unify the annotation scheme for all datasets, and jointly training models on different schemes will confuse the model in categorizing entities. In addition, the existing NER datasets are much smaller than those of the plain text used for the language modeling task, which will result in a less effective pre-training.