Abstract Relation extraction in the biomedical domain is a challenging task due to a lack of labeled data and a long-tail distribution of fact triples. Many works leverage distant supervision which automatically generates labeled data by pairing a knowledge graph with raw textual data. Dis- tant supervision produces noisy labels and requires additional techniques, such as multi-instance learning (MIL), to denoise the training signal. However, MIL requires multiple instances of data and struggles with very long-tail datasets such as those found in the biomedical domain. In this work, we propose a novel reformulation of MIL for biomedical relation extraction that abstracti- fies biomedical entities into their corresponding semantic types. By grouping entities by types, we are better able to take advantage of the benefits of MIL and further denoise the training signal. We show this reformulation, which we refer to as abstractified multi-instance learning (AMIL), improves performance in biomedical relationship extraction. We also propose a novel relationship embedding architecture that further improves model performance. Introduction Relation extraction (RE) is a key facet of information extraction in large bodies of unstructured textual data. RE is particularly important in the biomedical domain where extracting relationships between pairs of biomedical entities, also known as Ã¢ÂÂfact triplesÃ¢ÂÂ, can produce new insights into complicated biological interactions. For instance, with the near-exponential growth of microbiome research [SaÃ¢ÂÂed et al., 2019], advanced RE methods may help discover important links between gut microbiota and diseases. It is in this context that we motivate our work. RE within the biomedical domain comes with two inherent challenges: there are more than 30 million scientific articles, with hundreds of thousands of articles published every year, and there is a corresponding lack of labeled data. To resolve these challenges, many have leveraged distant supervision techniques which pair knowledge graphs with raw textual data to automatically generate labels to train deep-learning models [Gu et al., 2019, Su et al., 2019, Junge and Jensen, 2019]. We seek to improve distantly supervised biomedical RE methods in this work. We use the Unified Medical Language System (UMLS) Metathesaurus [Bodenreider, 2004] for our knowledge graph and pair it with raw textual data from PubMed [Canese and Weis, 2013]. To automatically generate labels, distantly supervised RE methods rely on a simple yet powerful assumption: any singular sentence that contains a pair of entities also expresses a relationship, as determined by the accompanying knowledge graph, between those entities [Mintz et al., 2009]. However, this assumption leads to a noisy training signal with many false positives as not all sentences express a relationship between an entity pair. To combat this, many works have leveraged multi- instance learning (MIL) [Riedel et al., 2010, Hoffmann et al., 2011, Zeng et al., 2015] where, instead of assessing single sentences, MIL assesses positive and negative bags of sentences that contain the same entity pair. Grouping sentences into bags greatly reduces noise in the training signal since a bag of sentences is more likely to express a relationship than a single sentence. This enables the model to better classify relationships between unseen entity pairs. However, similar to many NLP tasks, biomedical RE suffers from a long-tail distribution of fact triples, where many entity pairs are only supported by a few sentences of evidence. After processing the PubMed corpus, we observe that a majority (Ã¢ÂÂ¼ 52%) of extracted triples are supported by fewer than three sentences. Creating bags of sentences for such entity pairs requires heavy up-sampling. For example, if a pair of entities is only supported by one sentence and a bag size is equal to 16 sentences, the single sentence is duplicated 15 times to fill the bag. This erases the benefit of MIL. To counter this issue, we introduce abstractified multi-instance learning (AMIL) where, instead of grouping entity pairs by name, we group entities by the corresponding semantic type as determined by UMLS. UMLS categorizes each entity with a semantic type within the UMLS semantic network. The UMLS semantic network is curated by human experts for decades and provides a rich ontology of biomedical concepts which we leverage to group multiple different entity pairs within a single MIL bag, reducing the need to up-sample sentences. For example, consider two sentences: (1) a sentence containing the entity pair (fibula, tibia) and (2) a second sentence containing the entity pair (humerus, ulna). With distant supervision, we assume each sentence expresses the relationship linking both pairs, namely articulatesDespite expressing the same relationship, without abstraction, these sentences are placed into separate MIL bags since bags are grouped by distinct entity pairs. By introducing abstractified multi-instance learning, the entities fibula, tibia, humerus, and ulna are grouped by their corresponding UMLS semantic typeÃÂ¢ÃÂÃÂÃÂ¢ÃÂÃÂBody Part, Organ, or Organ Component.ÃÂ¢ÃÂÃÂ This allows the entity pair to automatically generate labels to train deep-learning models. However, similar to many NLP tasks, biomedical RE suffers from a long-tail distribution of fact triples, where many a triples relationship is formed by interactions between an entity pair. For instance, with the near-exponential growth of microbiome research [SaÃ¢ÂÂed et al., 2019], advanced RE methods may help discover important links between gut microbiota and diseases. It is in this context that we motivate our work. RE within the biomedical domain comes with two inherent challenges: there are more than 30 million scientific articles, with hundreds of thousands of articles published every year, and there is a corresponding lack of labeled data. To resolve these challenges, many have leveraged distant supervision techniques which pair knowledge graphs with raw textual data to automatically generate labels to train deep-learning models [Gu et al., 2019, Su et al., 2019, Junge and Jensen, 2019]. We seek to improve distantly supervised biomedical RE methods in this work. We use the Unified Medical Language System (UMLS) Metathesaurus [Bodenreider, 2004] for our knowledge graph and pair it with raw textual data from PubMed [Canese and Weis, 2013]. To automatically generate labels, distantly supervised RE methods rely on a simple yet powerful assumption: any singular sentence that contains a pair of entities also expresses a relationship, as determined by the accompanying knowledge graph, between those entities [Mintz et al., 2009]. However, this assumption leads to a noisy training signal with many false positives as not all sentences express a relationship between an entity pair. To combat this, many works have leveraged multi- instance learning (MIL) [Riedel et al., 2010, Hoffmann et al., 2011, Zeng et al., 2015] where, instead of assessing single sentences, MIL assesses positive and negative bags of sentences that contain the same entity pair. Grouping sentences into bags greatly reduces noise in the training signal since a bag of sentences is more likely to express a relationship than a single sentence. This enables the model to better classify relationships between unseen entity pairs. However, similar to many NLP tasks, biomedical RE suffers from a long-tail distribution of fact triples, where many triples relationships are formed by interactions between an entity pair. These entities are often labeled as follows:Ã¢ÂÂBody Part, Organ, or Organ Component.Ã¢ÂÂ This entity pair is most often found in the gastrointestinal tract, where bacteria are found to produce various types of biomedical entities. These entities are grouped by relatively simple yet powerful assumptions: since*/() is the best-fitting entity pair, and (II) is the worst-fitting entity pair. Because these entities are grouped by their corresponding UMLS semantic type, we assume each entity pair expresses the relationship it contains, regardless of UMLS type.