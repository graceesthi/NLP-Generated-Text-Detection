Abstract We model here an epistemic bias we call interpretive blindness (IB). IB is a special problem for learning from testimony, in which one acquires information only from text or conversation. We show that IB follows from a co-dependence between background beliefs and interpretation in a Bayesian setting and the nature of contemporary testimony. We argue that a particular characteristic contemporary testimony, argumentative completeness, can preclude learning in hierarchical Bayesian settings, even in the presence of constraints that are designed to promote good epistemic practices. INTRODUCTION In this paper, we describe and analyze an as far as we know theoretically un-examined kind of bias, which we call interpretive blindness(IB). IB is exemplified by humans (and perhaps soon by sophisticated machine learning algorithms) whose beliefs are guided and shaped by testimony. When learning through testimony—perhaps the primary way that most people acquire information nowadays—an agent acquires beliefs through conversations with other agents, or from books, newspapers or social networks, and so on. Typically, such people lack direct access to the phenomena described via that testimony. Typically too, humans only pay attention to a restricted set of bodies of testimony from a limited number of sources for their information—which makes sense in terms of an agent’s limited resources and attention span. Our paper is about the strategic consequences of opinion diffusion through testimony and the distortions on learning and information that can result. IB results from this restriction to few sources of testimony and a natural co-dependence between beliefs and interpretation (Asher and Paul, 2018). Relying on testimony T from a restricted set of sources to update one’s beliefs leads to the mutual reinforcement of our confidence in the source and our belief in T; this creates a bias that can preclude learning when an agent tries to exploit new data that are incompatible with or simply distinct from T. Agents who are interpretively blind will discount any evidence that challenges their beliefs. We use Wolpert’s 2018 extended Bayesian framework to prove our results. While IB is problematic for a standard Bayesian framework, it also poses problems for hierarchical Bayesian approaches (Gelman et al., 2013), because testimony from sources on social media like Facebook, 24/7 media outlets and web interest groups is often argumentatively complete, a notion we analyze precisely in Section 4; in an argumentatively complete body of testimony T, the authors of that testimony can respond to and argue with any doubts raised by other data or arguments in a body T ′ that might threaten T’s credibility. A skillful climate denier, for example, will always find a way to undercut the most scientifically careful argument. Argumentatively complete testimony thus can undermine higher order constraints and good epistemic practices that should guide first order learning. Our paper starts in Section ?? by discussing testimony. We then introduce the codependence of belief and interpretation and apply it to the situation of testimony and the sources that support it. In Section 3 we formally show how IB can result in ordinary Bayesian learning. Section 4 shows how IB is reinforced in a hierarchical Bayesian learning setting. Section 6 develops a game theoretic setting to investigate the complexity of IB. We provide results as to whether it is possible to free agents from interpretive bias in several epistemic settings.  Comparisons to Prior Work IB is an epistemological bias that is clearly related to confirmation bias (Lord et al., 1979; Nickerson, 1998; Oswald and Grosjean, 2004), in which agents interpret new evidence in a way that confirms their beliefs, and to the framing biases of Tversky and Kahneman (1975, 1985). People tend to see in the evidence what they believe. These forms of bias, however, concern how beliefs and bias influence interpretation, painting only part of the picture of IB (see also Asher and Paul (2018)). Further, unlike much of the psychological literature which finds epistemologically exogenous justifications for this bias (Dardenne and Leyens, 1995), we show how IB is a natural outcome of Bayesian updating, rational resource management and the belief interpretation co-dependence. IB is a concrete application of the work on bandits in, determining optimal allocation of resources to the exploration and exploitation of sources Whittle (1980); Lai and Robbins (1985); Banks and Sundaram (1994); Burnetas and Katehakis (1997); Auer et al. (2002); Cesa-Bianchi and Lugosi (2006); Garivier and Capp´e (2011). It is also related to work on generalization in machine learning. Epistemic biases affect generalization and learning capacity in ways that are still not fully understood (Lampinen and Vehtari, 2001; Zhang et al., 2016; Kawaguchi et al., 2017; Neyshabur et al., 2017). Zhang et al. (2016) show that standard techniques in machine learning for promoting good epistemic biases and generalization—training error minimization, regularization techniques like weight decay or dropout, or complexity measures used to minimize generalization error (the difference between training error and test error)—do not necessarily lead to good generalization and test performance. Argumentatively complete testimony T incorporates an adversarial attack mechanism against any good epistemic practices that might discount T. It’s this mechanism that guarantees IB. The argumentation literature (Amgoud and Demolombe, 2014; Dung, 1995) is also relevant to IB. If testimony T is argumentatively complete, then T always provides a counterargument to an attack against T–much like an acceptable argument in Dung (1995). In addition, however, an argumentatively complete T also supports higher order evaluation hypotheses that support hypotheses that support T. There are also important connections to the literature on trust (Castelfranchi and Falcone, 2010); in our set up learning agents trust certain sources over others, and our higher order setting invokes a hierarchy of reasons. Nevertheless, the argumentation and trust-based work of which we are aware is complementary to our approach. An argumentation framework takes a possibly inconsistent belief base and imposes a static constraint on inference in such a setting. Similarly, trust is typically modeled in some sort of static modal framework. By contrast, ME learning games and the whole Bayesian framework are dynamic, with beliefs evolving under evidence and game strategies evolving under agent interaction. It is this dynamic evolution that is crucial to our approach and, we think, to modeling agents and learning. In sum, we are not looking at the problem of consistency, but rather the problems of entrenchment and bias. Conclusions Interpretive blindness results from a dynamic, iterative process whereby a learner’s background beliefs and biases lead her to update her beliefs based on a body of testimony T, and then biases inherent in T come back to reinforce her beliefs and her trust in T’s source(s), further biasing her towards these sources for future updates. We have introduced and formally characterized IB. We have shown that IB can prevent learning even in higher order Bayesian frameworks for learning from argumentatively complete testimony, despite the presence of constraints designed to promote good epistemic practices. We also shown that IB is computationally complex as a co-r.e. set via a game theoretic analysis, and that an agent may rationally remain in IB in the face of epistemic arguments. Our game theoretic analysis can also be extended to cases where the agent falls out of IB but then is a recidivist and becomse a prisoner once more. We leave that for future work. Investigating IB alas is not just an academic enterprise. IB really does happen, with sometimes tragic or dangerous results. We think a careful formal analysis is urgent for society. Finally, we note that while we have focused on IB as a problem for learning from testimony, the problem it raises for learning extends to any case in which we do not have unmediated access to ground truth and our data is “theory laden” Hanson (1958).