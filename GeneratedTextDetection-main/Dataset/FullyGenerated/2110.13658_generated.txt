Abstract Recent impressive improvements in NLP, largely based on the success of contextual neural language models, have been mostly demonstrated on at most a couple dozen high- resource languages. Building language mod- els and, more generally, NLP systems for non- standardized and low-resource languages re- mains a challenging task. In this work, we fo- cus on North-African colloquial dialectal Ara- bic written using an extension of the Latin script, called NArabizi, found mostly on so- cial media and messaging communication. In this low-resource scenario with data display- ing a high level of variability, we compare the downstream performance of a character-based language model on part-of-speech tagging and dependency parsing to that of monolingual and multilingual models. We show that a character- based model trained on only 99k sentences of NArabizi and fined-tuned on a small treebank of this language leads to performance close to those obtained with the same architecture pre- trained on large multilingual and monolingual models. Confirming these results a on much larger data set of noisy French user-generated content, we argue that such character-based language models can be an asset for NLP in low-resource and high language variability settings. Introduction Current state-of-the-art monolingual and multi- lingual language models require large amounts of data to be trained, showing limited performance on low-resource languages (Howard and Ruder, 2018; Devlin et al., 2019). They lead to state-of-the-art results on most NLP tasks (Devlin et al., 2018; Raffel et al., 2020). In order to achieve high performance, these models rely on transfer learning archi- tectures: the language models need to be trained on large amounts of data (pre-training) to be able to transfer the acquired knowledge to a downstream task via fine-tuning on a relatively small number of examples, resulting in a significant performance improvement with respect to previous approaches. This dependency on large data sets for pre-training is a severe issue for low-resource languages, de- spite the emergence of large and successful multi- lingual pre-trained language models (Muller et al., 2021b). This is especially the case for languages with unusual morphological and structural features, which struggle to take advantage from similari- ties with high-resource, well represented languages such as Romance and Germanic languages. In this work, we focus on one of such highly challenging languages, namely North-African di- alectal Arabic. Its Latin transcription (Arabizi) dis- plays a high level of linguistic variability1, on top of scarce and noisy resource availability, making it a particularly challenging language for most NLP systems relying on pre-trained multilingual mod- els(Mulleretal.,2020).2 To Tackle The Resource scarcity issue regarding Arabic dialects, Antoun et al. (2020) use BERT architecture (Devlin et al., 2019) to train a model on Arabic text to compare this approach to standard multilingual models. In- deed, Martin et al. (2020) show that fine-tuning a monolingual model leads to better results than fine-tuning a multilingual one, meaning that when fine-tuning is used there is no significant perfor- mance improvement from cross-lingual transfer during pre-training. However, such model is still pre-trained on sentences written in a single lan- guage and was not trained to handle the presence of multiple languages in the same sentence (code- switching), a frequent phenomenon in NArabizi. However both monolingual and multilingual model approaches bear the risk of being lim- ited by a subword tokenization-based vocabu- lary when facing out-of-domain training data lan- guage, especially in high-variability noisy scenar- ios (El Boukkouri et al., 2020; Clark et al., 2021), even though Muller et al. (2020) demonstrated a positive effect for NArabizi when using target lan- guage data to fine-tune a multilingual language model on its own objective function before pre- training. Following a different approach, we investigate the use of a recently issued character-based lan- guage model (El Boukkouri et al., 2020) that was shown to display a remarkable robustness to lexi- cal variation and noise when facing a new distant domain, namely biomedical. The pipeline we de- veloped is simpleconsists in fine-tuning this character-based model for several tasks in a noisy low-resource language scenario. We show that a character-based model trained on only 99k sen- tences of NArabizi and fined-tuned on a small tree- bank of the language leads to performance close to that obtained with the same architecture pre- trained on large multilingual and monolingual mod- els (mBERT and CamemBERT). Interestingly, we generalize this observation by using the same architecture on a much larger French user-generated Content treebank that ex- hibits similar language variability issues than NAra- bizi. In fact, pre-training a character-based model on 1% of the large-scale French instance of the multilingual corpus OSCAR leads to similar per- formance as a subword based model trained on the full corpus, showing that such character-based lan- guage model can reach similar performance levels and that the resulting models exhibit the same tol- erance to noise as their much larger BERT counter- parts. This demonstrates the value of such models in very scarce resource scenario. Our code and models are freely available. Discussion In this work, we evaluate the benefits of using a character-based model in low-resource scenarios. Our results show that training such a model from scratch on much fewer data gives similar perfor- mance to a multilingual BERT adapted to the lan- guage using the same amount of data. Overall, our observations confirm the findings of El Boukkouri et al. (2020) regarding the robust- ness to noise and misspellings of the Character- BERT model. We showed that the model has com- petitive performance on noisy French UGC data when trained on only a fraction of the OSCAR corpus compared to CamemBERT trained on the full corpus and when trained on corpora containing about 1M words in the extremely noisy and low- resource case of NArabizi. This is consistent with the findings of Martin et al. (2020) and Micheli et al. (2020), who showed that MLM could already learn a lot from pre-training on smaller data set. Extending this investigation by training on a larger amount of data could help to explore the ability of the model to handle highly variable noisy data. However, one could question the usefulness of such Character-BERT based models if small Bert- based models were available on the same domain. To build an answer to that question, we conducted a quick set of experiments comparing our char- acterBert model trained on 1% of Oscar with the off-the-shelf Camembert version trained on 4gb of the Oscar corpus French instance (2.38% of the full corpus) and which was shown to perform al- most as well as the full model (Martin et al., 2020) on many downstream tasks. Both models were fined-tuned according to our MODEL+Task archi- tecture on either the FSMB or the Sequoia treebank, allowing us to evaluate their in-domain and out-of- domain performance. Results on Table 8 confirm the effectiveness of our characterBert model with overall better results than CamemBERT4gb in the in-domain scenario and similar, if not slightly bet- ter in the out-of-domain scenario, except for the labeled attachment score (75.83 vs 75.39). The fact that CamemBERT4gb was trained on more than twice as much data and with 200k pre-training steps while the characterBert pre-training stopped below 20k steps probably explains this small dis- crepancy but further investigations are needed with a fully parallel setting where both characterBert and CamemBERT are pretrained on the same amount of data and the same hyper-parameters. The take- home message from this in-domain experiments is that CharacterBert seems to be able to better cap- ture at least some of the UGC idiosyncracies that are prevalent in the FSMB (Seddah et al., 2012b) than its Bert-based counterparts. This was also shown by Rosales NuÃÂnÃÂez et al. (2021) in the con- text of character-based neural machine translation. Interestingly, their results showed that transformer- based models with subword tokenization also ex- hibit strong robustness to a certain type of lex- ical noise. This behavior has been very recently demonstrated by (Itzhak and Levy, 2021) and could explain why the BERT-based models weper- formed so well in our experiments. The key seems to be relying on the ability of the subword distri- bution to model some forms of lexical variations. Much more experiments are needed to clearly in- vestigate in what circumstances, besides noisy and resource-scarce scenarios, characterBERT models bring in a decisive advantage. In this work, we fo- cus on North-African colloquial dialectal Ara- bic written using an extension of the Latin script, called NArabizi, found mostly on so- cial media and messaging communication. In this low-resource scenario with data display- ing a high level of variability, we compare the downstream performance of a character-based language model on part-of-speech tagging and dependency parsing to that of monolingual and multilingual models. We show that a character- based model trained on only 99k sentences of NArabizi and fined-tuned on a small treebank of this language leads to performance close to those obtained with the same architecture pre- trained on large multilingual and monolingual models. Confirming these results a on much larger data set of noisy French user-generated content, we argue that such character-based language models can be an asset for NLP in low-resource and high language variability settings. Introduction Current state-of-the-art monolingual and multi- lingual language models require large amounts of data to be trained, showing limited performance on low-resource languages (Howard and Ruder, 2018; Devlin et al., 2019). They lead to state-of-the-art results on most NLP tasks (Devlin et al., 2018; Raffel et al., 2020). In order to achieve high performance, these models rely on transfer learning archi- tectures: the language models need to be trained on large amounts of data (pre-training) to be able to transfer the acquired knowledge to a downstream task via fine-tuning on a relatively small number of examples, resulting in a significant performance improvement with respect to previous approaches. This dependency on large data sets for pre-training is a severe issue for low-resource languages, de- spite the emergence of large and successful multi- lingual pre-trained language models (Muller et al., 2021b).