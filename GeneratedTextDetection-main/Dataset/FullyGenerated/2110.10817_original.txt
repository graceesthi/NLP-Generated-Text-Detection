Abstract We provide a hands-on introduction to optimized textual sentiment indexation using the R package sentometrics. Textual sentiment analysis is increasingly used to unlock the potential information value of textual data. The sentometrics package implements an intuitive framework to efficiently compute sentiment scores of numerous texts, to aggregate the scores into multiple time series, and to use these time series to predict other variables. The workflow of the package is illustrated with a built-in corpus of news articles from two major U.S. journals to forecast the CBOE Volatility Index. Keywords: Aggregation, Penalized Regression, Prediction, R, sentometrics, Textual Senti- ment, Time Series. Introduction Individuals, companies, and governments continuously consume written material from various sources to improve their decisions. The corpus of texts is typically of a high-dimensional longitudinal nature requiring statistical tools to extract the relevant information. A key source of information is the sentiment transmitted through texts, called textual sentiment. Algaba, Ardia, Bluteau, Borms, and Boudt (2020) review the notion of sentiment and its applications, mainly in economics and finance. They define sentiment as “the disposition of an entity towards an entity, expressed via a certain medium.” The medium in this case is texts. The sentiment expressed through texts may provide valuable insights on the future dynamics of variables related to firms, the economy, political agendas, product satisfaction, and marketing campaigns, for instance. Still, textual sentiment does not live by the premise to be equally useful across all applications. Deciphering when, to what degree, and which layers of the sentiment add value is needed to consistently study the full information potential present within qualitative communications. The econometric approach of constructing time series of sentiment by means of optimized selection and weighting of textual sentiment is referred to as sentometrics by Algaba et al. (2020) and Ardia, Bluteau, and Boudt (2019). The term sentometrics is a composition of (textual) sentiment analysis and (time series) econometrics. The release of the R (R Core Team 2021) text mining infrastructure tm (Feinerer, Hornik, and Meyer 2008) over a decade ago can be considered the starting point of the development and popularization of textual analysis tools in R. A number of successful follow-up attempts at improving the speed and interface of the comprehensive natural language processing capabil- ities provided by tm have been delivered by the packages openNLP (Hornik 2019), cleanNLP (Arnold 2017), quanteda (Benoit, Watanabe, Wang, Nulty, Obeng, Müller, and Matsuo 2018), tidytext (Silge and Robinson 2016), and qdap (Rinker 2020). The notable tailor-made packages for sentiment analysis in R are meanr (Schmidt 2019), SentimentAnalysis (Feuerriegel and Proellochs 2021), sentimentr (Rinker 2019b), and syuzhet (Jockers 2020). Many of these packages rely on one of the larger above-mentioned textual analysis infrastructures. The meanr package computes net sentiment scores fastest, but offers no flexibility.1 The SentimentAnalysis package relies on a similar calculation as used in tm’s sentiment scoring function. The package can additionally be used to generate and evaluate sentiment dictionaries. The sentimentr package extends the polarity scoring function from the qdap package to handle more difficult linguistic edge cases, but is therefore slower than packages which do not attempt this. The SentimentAnalysis and syuzhet packages also become comparatively slower for large input corpora. The quanteda and tidytext packages have no explicit sentiment computation function but their toolsets can be used to construct one. Our R package sentometrics proposes a well-defined modeling workflow, specifically targeted at studying the evolution of textual sentiment and its impact on other quantities. It can be used (i) to compute textual sentiment, (ii) to aggregate fine-grained textual sentiment into various sentiment time series, and (iii) to predict other variables with these sentiment measures. The combination of these three facilities leads to a flexible and computationally efficient framework to exploit the information value of sentiment in texts. The package presented in this paper therefore addresses the present lack of analytical capability to extract time series intelligence about the sentiment transmitted through a large panel of texts. Furthermore, the sentometrics package positions itself as both integrative and supplementary to the powerful text mining and data science toolboxes in the R universe. It is integrative, as it combines the strengths of quanteda and stringi (Gagolewski 2021) for corpus construction and manipulation. It uses data.table (Dowle and Srinivasan 2021) for fast aggregation of textual sentiment into time series, and glmnet (Friedman, Hastie, and Tibshirani 2010) and caret (Kuhn 2021) for (sparse) model estimation. It is supplementary, given that it easily extends any text mining workflow to compute, aggregate and predict with textual sentiment.  The remainder of the paper is structured as follows. Section 2 introduces the methodology behind the R package sentometrics. Section 3 describes the main control functions and illustrates the package’s typical workflow. Section 4 applies the entire framework to forecast the Chicago Board Options Exchange (CBOE) Volatility Index. Section 5 concludes. Conclusion and future development The R package sentometrics provides a framework to calculate sentiment for texts, to aggregate textual sentiment scores into many time series at a desired frequency, and to use these in a flexible prediction modeling setup. It can be deployed to quantify a qualitative corpus of texts, relate it to a target variable, and retrieve which type of sentiment is most informative through visualization and attribution analysis. The main priorities for further development are integrating better prediction tools, enhancing the complexity of the sentiment engine, allowing user-defined weighting schemes, and adding intra-day aggregation.