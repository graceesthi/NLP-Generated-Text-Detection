Abstract In this paper, we introduce EmpBot: an endto-end empathetic chatbot. Empathetic conversational agents should not only understand what is being discussed, but also acknowledge the implied feelings of the conversation partner and respond appropriately. To this end, we propose a method based on a transformer pretrained language model (T5). Specifically, during finetuning we propose to use three objectives: response language modeling, sentiment understanding, and empathy forcing. The first objective is crucial for generating relevant and coherent responses, while the next ones are significant for acknowledging the sentimental state of the conversational partner and for favoring empathetic responses. We evaluate our model on the EmpatheticDialogues dataset using both automated metrics and human evaluation. The inclusion of the sentiment understanding and empathy forcing auxiliary losses favor empathetic responses, as human evaluation results indicate, comparing with the current state-of-the-art. Introduction Since dialogue is regarded as a fundamental and complex element of human cognition (Jurafsky and Martin, 2000), the development of systems capable of understanding human language and communicating with humans can have a significant impact. However, human communication requires the acknowledgment and the exchange of conversational partner’s emotions, as emotions play an important role in developing a confidential relationship between the speaker and the listener. Open domain conversational agents have been widely studied in the past years and both retrievalbased and generation-based approaches (Wu et al., 2019; Cai et al., 2019; Weston et al., 2018) have been developed. However, prior research has shown that most of those conversational agents are unable to imitate dialogues between humans, as the produced responses are generic and short (Vinyals and Le, 2015; Li et al., 2016b). Several efforts have been made to make the conversationa more engaging by keeping track of the conversational context (Sordoni et al., 2015b,a; Serban et al., 2016, 2017) or by producing more diverse responses (Li et al., 2016a,c). Subsequently, a recent trend that was followed by various researchers (Li et al., 2016b; Zhang et al., 2018; Kulikov et al., 2019; Joshi et al., 2017; Zemlyanskiy and Sha, 2018; Mazaré et al., 2018; Dinan et al., 2020; Madotto et al., 2019; Hancock et al., 2019; Yavuz et al., 2019; Wolf et al., 2019) in order to make the responses more coherent and consistent through the dialogue, was to produce personalized responses by conditioning the generation on a persona profile. Apart from understanding what is being discussed, a conversational agent should also acknowledge the emotional state of the conversational partner, as it is a significant part of human communication. A lot of researchers have focused on detecting emotion (Fan et al., 2018b; Xu et al., 2018; Winata et al., 2017, 2019) and empathy in dialogue systems (Bertero et al., 2016; Chatterjee et al., 2019). Zhou et al., 2018 introduced a seq2seq (Sutskever et al., 2014) Emotional Chatting Machine in order to generate responses with high emotional context, using emotional embeddings and an internal and external memory mechanism. A GAN-based (Goodfellow et al., 2014) framework was also proposed by Wang and Wan, 2018 that controlled the sentiment of the generated response. Wu and Wu, 2019 also used a dual-decoder to similarly generate emotional responses, given the sentiment. Zhou and Wang, 2018 introduced a Twitter dataset which used the emojis of the Twitter posts as emotionlabels and they also proposed a seq2seq model to generate emotional responses. Lubis et al., 2018 introduced a new dataset and proposed a hierarchical seq2seq response generator for affect-sensitive dialogue generation. Rashkin et al., 2019 introduced the EmpatheticDialogues dataset and trained the baselines to generate empathetic responses and simultaneously predict the corresponding emotion of the dialogue context. Later, Lin et al., 2019 introduced the "Mixture of Empathetic Listeners" framework improving the initial baselines. Santhanam and Shaikh, 2019 finetuned the GPT2 (Radford et al., 2019) model to improve the results further, while Shin et al., 2019 used reinforcement learning for predicting the user’s sentiment look-ahead along side with response generation. Lin et al., 2019 improved the performance on EmpatheticDialogues by finetuning the GPT2 model with the use of multitask learning, while Majumder et al., 2020 followed a different approach introducing stochasticity into the emotion mixture and arguing that empathetic responses do not always mirror the emotion of the user. Significant improvements were also made by Roller et al., 2021 and Shuster et al., 2020 who used multi-task training on multiple dialog tasks, achieving state-of-the-art results. In this work, in order to enforce empathetic response generation we propose a method based on a transformer pretrained language model (T5). Specifically, during finetuning we use three objectives: response language modeling, sentiment understanding and empathy forcing. The sentiment understanding objective is crucial for tracking and acknowledging the emotional state of the conversational partner, while the empathy forcing objective favors empathetic response generation by penalizing responses that have an opposite sentiment of that of the conversational partner. Our key contribution is the inclusion of the sentiment understanding and empathy forcing auxiliary losses to promote empathetic behavior. The proposed approach, EmpBot, 1 , is on par with state-of-the-art in terms of BLEU score. However, our model produces significantly more fluent and empathetic responses, as indicated by human evaluation results. Conclusions In this work we propose EmpBot, a T5-based chatbot, augmented with a novel finetuning procedure for generating empathetic dialogue responses. The proposed loss consists of three parts: an LM loss that produces valid textual responses, a sentiment classification loss that introduces emotional awareness to the model and an empathy forcing loss that ensures that the responses are emotionally relevant. We evaluate EmpBot using standard evaluation metrics, i.e. perplexity and BLEU score, achieving state-of-the-art results. Our human evaluation results indicate that EmpBot produces more fluent and empathetic responses, when compared with both the baseline and the state-of-the-art models. In the future we want to extend the proposed method for other architectures, and explore more empathy forcing losses using raw emotion values instead of sentiment polarities.