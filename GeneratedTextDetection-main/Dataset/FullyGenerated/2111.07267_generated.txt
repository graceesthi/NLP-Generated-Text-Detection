Abstract Definitions are essential for term understand- ing. Recently, there is an increasing interest in extracting and generating definitions of terms automatically. However, existing approaches for this task are either extractive or abstractiveÃÂ¢ÃÂÃÂ definitions are either extracted from a corpus or generated by a language generation model. In this paper, we propose to combine extrac- tion and generation for definition modeling: first extract self- and correlative definitional in- formation of target terms from the Web and then generate the final definitions by incorpo- rating the extracted definitional information. Experiments demonstrate our framework can generate high-quality definitions for technical terms and outperform state-of-the-art models for definition modeling significantly. Introduction Definitions of terms are highly summarized sen- tences that capture the main characteristics of terms. To understand a term, the most straightforward way is to read its definition. Recently, acquiring defini- tions of terms automatically has aroused increasing interest. There are two main approaches: extractive, corresponding to definition extraction, where defi- nitions of terms are extracted from existing corpora automatically (Anke and Schockaert, 2018; Veyseh et al., 2020; Kang et al., 2020); and abstractive, corresponding to definition generation, where defi- nitions of terms are generated conditioned with the target terms and their contexts (Noraset et al., 2017; Gadetsky et al., 2018; Bevilacqua et al., 2020). However, both extractive and abstractive ap- proaches have their limitations. For instance, ex- tracting high-quality definitions for terms would be difficult due to the incompleteness and low quality of data sources. Generating definitions for terms would be challenging if terms are technical (e.g., need domain knowledge to understand) while the contexts cannot provide sufficient knowledge. Con- sequently, existing models perform poorly on tech- nical terms. In our human evaluation, we find most definitions produced by the state-of-the-art abstrac- tive model contain wrong information. Fortunately, definition extraction and definition generation can complement each other. On one hand, definition generator has the potentials to help the extractor by refining and synthesizing the ex- tracted definitions; on the other hand, definition ex- tractor can retrieve useful definitional information as knowledge for the generator to produce defini- tions. However, surprisingly, existing works are either extractive or abstractive, even do not connect and compare them. Therefore, in this work, we propose to combine definition extraction and definition generation for definition modeling. We achieve this by introduc- ing a framework consisting of two processes: ex- traction, where definitional information of terms are extracted from the Web; and generation, where the final definitions are generated with the help of the extracted definitional information. We build models for extraction and generation based on Pre-Trained Language Models (Devlin et al., 2019; Lewis et al., 2020; Brown et al., 2020). Specifically, for extraction, we propose a BERT- based definition extractor to extract self-definitional information (i.e., definitional sentences of the target term). We also suggest that related terms can help defining the target term and leverage Wikipedia as the external knowledge source to retrieve correl- ative definitional information (i.e., definitions of related terms). For generation, we design a BART- based definition generator to produce the final defi- nition by incorporating the extracted knowledge. From another perspective, we propose to reform the problem of definition modeling, which is pre- viously mainly defined as generating definitions of terms conditioned with a target term and a given context. Instead, we restudy this problem as defin- ing terms with extracted knowledge. This setting is in line with human behavior: to understand a term, compared to reading the given sentence it is used in, it is more straightforward and helpful to search and read its relevant content on the Internet. Our framework for definition modeling is simple and flexible that can easily be further expanded by leveraging more advanced language models. Ex- perimental results demonstrate our simple model outperforms state-of-the-art models significantly (e.g., BLEU score from 8.76 to 22.66, human an- notated score from 2.34 to 4.04), with several inter- esting findings: 1) for computer science terms, our extractive model can achieve performance compa- rable to (even better than) state-of-the-art abstrac- tive models; 2) both self- and correlative defini- tional informationsignificant to define a term; 3) the quality of definitions generated by our best model is high, while the state-of-the-art models suffer severely from hallucinations, i.e., generating irrelevant or contradicted facts. Our contributions are summarized as follows: As far as we know, we are the first to connect and combine definition extraction and definition generationÃ¢ÂÂ a simple idea that can significantly improve the performance of definition modeling. We propose to combine definition extraction and definition generation for definition modeling: first extract self- and correlative definitional in- formation of target terms from the Web and then generate the final definitions by incorpo- rating the extracted definitional information. Experiments demonstrate our framework can generate high-quality definitions for technical terms and outperform state-of-the-art models for definition modeling significantly. Introduction Definitions of terms are highly summarized sen- tences that capture the main characteristics of terms. To understand a term, the most straightforward way is to read its definition. Recently, acquiring defini- tions of terms automatically has aroused increasing interest. There are two main approaches: extractive, corresponding to definition extraction, where defi- nitions of terms are extracted from existing corpora automatically (Anke and Schockaert, 2018; Veyseh et al., 2020; Kang et al., 2020); and abstractive, corresponding to definition generation, where defi- nitions of terms are generated conditioned with the target terms and their contexts (Noraset et al., 2017; Gadetsky et al., 2018; Bevilacqua et al., 2020). However, both extractive and abstractive ap- proaches have their limitations. For instance, ex- tracting high-quality definitions for terms would be difficult due to the incompleteness and low quality of data sources. Generating definitions for terms would be challenging if terms are technical (e.g., need domain knowledge to understand) while the contexts cannot provide sufficient knowledge. Con- sequently, existing models perform poorly on tech- nical terms. In our human evaluation, we find most definitions produced by the state-of-the-art abstrac- tive model contain wrong information. Fortunately, definition extraction and definition generation can complement each other. On one hand, definition generator has the potentials to help the extractor by refining and synthesizing the ex- tracted definitions; on the other hand, definition ex- tractor can retrieve useful definitional information as knowledge for the generator to produce defini- tions. 