Abstract We model here an epistemic bias we call interpretive blindness (IB). IB is a special problem for learning from testimony, in which one acquires information only from text or conversation. We show that IB follows from a co-dependence between background beliefs and interpretation in a Bayesian setting and the nature of contemporary testimony. We argue that a particular characteristic contemporary testimony, argumentative completeness, can preclude learning in hierarchical Bayesian settings, even in the presence of constraints that are designed to promote good epistemic practices. INTRODUCTION In this paper, we describe and analyze an as far as we know theoretically un-examined kind of bias, which we call interpretive blindness(IB). IB is exemplified by humans (and perhaps soon by sophisticated machine learning algorithms) whose beliefs are guided and shaped by testimony. When learning through testimonyÃ¢ÂÂperhaps the primary way that most people acquire information nowadaysÃ¢ÂÂan agent acquires beliefs through conversations with other agents, or from books, newspapers or social networks, and so on. Typically, such people lack direct access to the phenomena described via that testimony. Typically too, humans only pay attention to a restricted set of bodies of testimony from a limited number of sources for their informationÃ¢ÂÂwhich makes sense in terms of an agentÃ¢ÂÂs limited resources and attention span. Our paper is about the strategic consequences of opinion diffusion through testimony and the distortions on learning and information that can result. IB results from this restriction to few sources of testimony and a natural co-dependence between beliefs and interpretation (Asher and Paul, 2018). Relying on testimony T from a restricted set of sources to update oneÃ¢ÂÂs beliefs leads to the mutual reinforcement of our confidence in the source and our belief in T; this creates a bias that can preclude learning when an agent tries to exploit new data that are incompatible with or simply distinct from T. Agents who are interpretively blind will discount any evidence that challenges their beliefs. We use WolpertÃ¢ÂÂs 2018 extended Bayesian framework to prove our results. While IB is problematic for a standard Bayesian framework, it also poses problems for hierarchical Bayesian approaches (Gelman et al., 2013), because testimony from sources on social media like Facebook, 24/7 media outlets and web interest groups is often argumentatively complete, a notion we analyze precisely in Section 4; in an argumentatively complete body of testimony T, the authors of that testimony can respond to and argue with any doubts raised by other data or arguments in a body T Ã¢ÂÂ² that might threaten TÃ¢ÂÂs credibility. A skillful climate denier, for example, will always find a way to undercut the most scientifically careful argument. Argumentatively complete testimony thus can undermine higher order constraints and good epistemic practices that should guide first order learning. Our paper starts in Section ?? by discussing testimony. We then introduce the codependence of belief and interpretation and apply it to the situation of testimony and the sources that support it. In Section 3 we formally show how IB can result in ordinary Bayesian learning. Section 4 shows how IB is reinforced in a hierarchical Bayesian learning setting. Section 6 develops a game theoretic setting to investigate the complexity of IB. We provide results as to whether it is possible to free agents from interpretive bias in several epistemic settings. Comparisons to Prior Work IB is an epistemological bias that is clearly related to confirmation bias (Lord et al., 1979; Nickerson, 1998; Oswald and Grosjean, 2004), in which agents interpret new evidence in a way that confirms their beliefs, and to the framing biases of Tversky and Kahneman (1975, 1985). People tend to see in the evidence what they believe. These forms of bias, however, concern how beliefs and bias influence interpretation, painting only part of the picture of IB (see also Asher and Paul (2018)). Further, unlike much of the psychological literature which finds epistemologically exogenous justifications for this bias (Dardenne and Leyens, 1995), we show how IB is a natural outcome of Bayesian updating, rational resource management and the belief interpretation co-dependence. IB is a concrete application of the work on bandits in, determining optimal allocation of resources to the exploration and exploitation of sources Whittle (1980); Lai and Robbins (1985); Banks and Sundaram (1994); Burnetas and Katehakis (1997); Auer et al. (2002); Cesa-Bianchi and Lugosi (2006); Garivier and CappÃÂ´e (2011). It is also related to work on generalization in machine learning. Epistemic biases affect generalization andcapacity in ways that are still not fully understood (Lampinen and Vehtari, 2001; Zhang et al., 2016; Kawaguchi et al., 2017; Neyshabur et al., 2017). Zhang et al. (2016) show that standard techniques in machine learning for promoting good epistemic biases and generalizationÃÂ¢ÃÂÃÂtraining error minimization, regularization techniques like weight decay or dropout, or complexity measures used to minimize bias (the difference between training error and test error, which can preclude learning when an agent tries to exploit new data that are incompatible with or simply distinct from T. Agents who are interpretively blind will discount any evidence that challenges their beliefs. We use WolpertÃ¢ÂÂs 2018 extended Bayesian framework to prove our results. While IB is problematic for a standard Bayesian framework, it also poses problems for hierarchical Bayesian approaches (Gelman et al., 2013), because testimony from sources on social media like Facebook, 24/7 media outlets and web interest groups is often argumentatively complete, a notion we analyze precisely in Section 4; in an argumentatively complete body of testimony T, the authors of that testimony can respond to and argue with any doubts raised by other data or arguments in a body T Ã¢ÂÂ² that might threaten TÃ¢ÂÂs credibility. A skillful climate denier, for example, will always find a way to undercut the most scientifically careful argument. Argumentatively complete testimony thus can undermine higher order constraints and good epistemic practices that should guide first order learning. Our paper starts in Section ?? by discussing testimony. We then introduce the codependence of belief and interpretation and apply it to the situation of testimony and the sources that support it. In Section 3 we formally show how IB can result in ordinary Bayesian learning. Section 4 shows how IB is reinforced in a hierarchical Bayesian learning setting. Section 6 develops a game theoretic setting to investigate the complexity of IB. We provide results as to whether it is possible to free agents from interpretive bias in several epistemic settings. Comparisons to Prior Work IB is an epistemological bias that is clearly related to confirmation bias (Lord et al., 1979; Nickerson, 1998; Oswald and Grosjean, 2004), in which agents interpret new evidence in a way that confirms their beliefs, and to the framing biases of Tversky and Kahneman (1975, 1985). People tend to see in the evidence what they believe. These forms of bias, however, concern how beliefs and bias influence interpretation, painting only part of the picture of IB (see also Asher and Paul (2018)). Further, unlike much of the psychological literature which finds epistemologically exogenous justifications for this bias (Dardenne and Leyens, 1995), we show how IB is a natural outcome of Bayesian updating, rational resource management and the belief interpretation co-dependence. IB is a concrete application of the work on bandits in, determining optimal allocation of resources to the exploration and exploitation of sources Whittle (1980); Lai and Robbins (1985); Banks and Sundaram (1994); Burnetas and Katehakis (1997); Auer et al. (2002); Cesa-Bianchi and Lugosi (2006); Garivier and CappÃÂ´e (2011).