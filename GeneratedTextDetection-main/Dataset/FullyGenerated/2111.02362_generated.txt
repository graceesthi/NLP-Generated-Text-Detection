Abstract This paper introduces the hmBlogs corpus for Persian, as a low resource language. This corpus has been prepared based on a collection of nearly 20 million blog posts over a period of about 15 years from a space of Persian blogs and includes more than 6.8 billion tokens. It can be claimed that this corpus is currently the largest Persian corpus that has been prepared independently for the Persian language. This corpus is presented in both raw and preprocessed forms, and based on the preprocessed corpus some word embedding models are produced. By the provided models, the hmBlogs is compared with some of the most important corpora available in Persian, and the results show the superiority of the hmBlogs corpus over the others. These evaluations also present the importance and effects of corpora, evaluation datasets, model production methods, different hyperparameters and even the evaluation methods. In addition to evaluating the corpus and its produced language models, this research also presents a semantic analogy dataset. Keywords Persian Corpus, Blog, Word Embedding, Analogy Test Set Introduction Language corpora are basic resources in natural language processing (NLP). These corpora range from small to very big (including billions of words). They can include just raw text or have some meta-data such as tags and annotations. As a general rule, it can be said that a larger corpus leads to a more useful corpus. This is especially the case when the main reliance is on statistical methods. Persian (Farsi) has an especially wide range of speakers across the world, specifically in Iran, Tajikistan and Afghanistan and is used as either a native or second language. It is, therefore, especially important to develop the necessary NLP tools and resources for this language. A major downfall of Persian as a low resource language is its lack of sufficiently large, covered and up-to-date corpora. In recent years, the use of language models based on word embeddings has become a common phenomenon. These models are not only crucial and practical on their own, but also have deep neural networks applications. These models are produced by the corpora and their quality strongly depends to the used corpora. A basic requirement for a corpus is its ability to represent the language adequately and incorporate the necessary genres and domains. The Persian language, however, lacks a widely available corpus with such features. The hmBlogs corpus is presented in this research as a large, accessible, public and diverse corpus of various language genres, and some of the word embedding models prepared by the hmBlogs corpus are also included. A set of analogy dataset prepared to evaluate this corpus is provided alongside, and the hmBlogs corpus is compared and evaluated based on the present dataset and two other datasets with some of the most important available Persian corpora. Related work Among the various corpora (with different dimensions and areas) prepared for the Persian language, some are private and publicly unavailable and others are either publicly available or accessible to researchers. It can be claimed that the volume and variety of corpora available for the Persian language is much less than that available for other languages such as English, which is a laboratory language. Corpora can be obtained from different news websites, newspapers and magazines, books, blogs and tweets, and etc. Due to a lack of Persian content on the Internet in the past years, older sources, such as the Hamshahri corpus (AleAhmad et al., 2009), rely less on Internet-created data. Newer corpora, such as the MirasText (Sabeti et al., 2018), on the other hand, are made only from the Persian content found on the Internet; and, even the presence of snippets is due to the publication of those snippets on the Internet. The Hamshahri corpus (AleAhmad et al., 2009) is one of the oldest Persian corpora and was founded on the compilation of news and articles of the Hamshahri newspaper, one of the most famous newspapers in Iran. It contains more than 166 thousand news and more than 63 million words. Its content is dated between the years 1996 and 2002. Articles in this corpus are labeled in 12 main thematic categories. One problem with this corpus is its lack of up-to- date content, which means that it fails to include certain important language and content changes such as changes in language and linguistic framing, semantic drifts and appearing new names and events. Due to its news nature, it is also devoid of the different types of language uses common among Persian speakers. An advantage of this corpus, however, is its accuracy and lack of typographical errors of the compiled text. Peykareh (Bijankhanal., 2011) is another early popular Persian corpus for NLP applications. This corpus contains 100 million words from a collection of news, web sites, and written sources. Peykareh texts range from the year 1978 to 2003. An important feature of this corpus from an NLP stance is its POS tagging, which is done semi-automatically. Of course, only about one tenth of this corpus has been labeled. Based on the word embedding training and the fact that its latest texts were compiled before 2004, Peykareh is a corpus of old texts. Furthermore, its size may not be large enough to make appropriate word embedding models. Another important resource used in NLP field is Wikipedia. The Persian Wikipedia (FaWiki) was launched in December 2003 and contained more than 775,000 articles by March 2021 (Ã¢ÂÂPersian Wikipedia,Ã¢ÂÂ 2021). Persian is currently the 19th language on Wikipedia (List of Wikipedias, n.d.). Like the Hamshahri corpus, the FaWiki has an official language that cannot cover all language types. Furthermore, due to its encyclopedic nature, a large number of Wikipedia articles are too specialized for Persian speakers and everyday usage. For example, the vast majority of Persian speakers do not know the capital, or currency of many countries. Or many people are unfamiliar with the names of drugs, programming languages or specialized topics in astronomy or anatomy. The existence of such articles and the preparation of word embedding based on such can cause incorrect bias and a disconnect between the obtained model and the real language of the people. Of course, an important advantage of Wikipedia compared to others is its constant updates and continuous expansion. IrBlogs (AleAhmad et al., 2016) is a corpus that has been created by crawling Persian blogs. Blogs are one of the most important resources for making corpora and are a valuable and rich source of a variety of texts due to a diversity of authors and topics. IrBlogs is the result of the crawl of more than 564 thousand blogs and includes nearly 5 million posts. It contains posts collected from 2002 to 2013 to study the Persian blogging space. This corpus also includes posts that are not in Persian. The existence of posts with other languages impairs the preparation of a suitable language model. Also, the newest texts of irBlogs are about 7 years old and do not include the most recent changes such as new names and events. Another text corpus prepared for the Persian language is the MirasText (Sabeti et al., 2018). When published in 2018, the MirasText was considered to be the largest corpus available in Persian. It contains about 2.8 million documents and about 1.4 billion words collected from around 250 websites, of which at least 150 sites of them are news websites. In addition to plain text, this corpus provides information, such as titles, descriptions, and keywords for its documents. The Persian Raw Text (PRT) (Persiannlp/Persian-Raw-Text, 2020/2021) is a corpus provided by putting together a variety of Persian corpora (including MirasText and FaWiki) and is not produced independently. Also, no special processing has been performed on it to detect any duplication. The main part of PRT is obtained from the Persian section of the Common Crawl project (Common Crawl, n.d.). Common Crawl is a web crawl project that crawls and collects resources available on the web in any language, including some in Persian. PRT is larger than hmBlogs in size, but as shown in the evaluation section, it scores lower than hmBlogs. Conclusion This paper aimed to introduce a large, open and general corpus for the Persian language, as a low resource language. The introduced corpus is, by far, the largest of all the few independent and publicly available Persian corpora (with the exception of PRT, which is not an independent corpus but a collection of several corpora). The hmBlogs corpus is a rather large corpus even when compared to the English corpora (for example see (English Corpora, n.d.)). HmBlogs has had the latest style of Persian writing in recent years and has preserved texts from the last 15 years in the Persian blog space. HmBlogs showed overall better performance than other corpora such as irBlogs, PRT and FaWiki in word embedding models. A new analogy dataset, (FATS), was also presented as a side product of this research along with the obtained models. Also all factors including the corpora, evaluation data, evaluation methods, model construction methods and hyperparameters were found to have notable effects on the evaluationOne of the challenges is keeping such corpora up to date. To solve this problem, it may be necessary to design processes that can keep corpora with the latest changes and adding new content. Designing such a process and its related systems could be a topic for future studies. The Persian language, however, lacks a widely available corpus with such features. The hmBlogs corpus is presented in this research as a large, accessible, public and diverse corpus of various language genres, and some of the word embedding models prepared by the hmBlogs corpus are also included. A set of analogy dataset prepared to evaluate this corpus is provided alongside, and the hmBlogs corpus is compared and evaluated based on the present dataset and two other datasets with some of the most important available Persian corpora. Related work Among the various corpora (with different dimensions and areas) prepared for the Persian language, some are private and publicly unavailable and others are either publicly available or accessible to researchers. It can be claimed that the volume and variety of corpora available for the Persian language is much less than that available for other languages such as English, which is a laboratory language.