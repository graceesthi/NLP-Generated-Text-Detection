Abstract The enormous amount of data being generated on the web and social media has increased the demand for detecting online hate speech. Detecting hate speech will reduce their neg-ative impact and influence on others. A lot of effort in the Natural Language Processing (NLP) domain aimed to detect hate speech in general or detect specific hate speech such as religion, race, gender, or sexual orientation. Hate communities tend to use abbreviations, intentional spelling mistakes, and coded words in their communication to evade detection, adding more challenges to hate speech detec-tion tasks. Thus, word representation will play an increasingly pivotal role in detecting hate speech. This paper investigates the feasibil-ity of leveraging domain-specific word embed-ding in Bidirectional LSTM based deep model to automatically detect/classify hate speech. Furthermore, we investigate the use of the transfer learning language model (BERT) on hate speech problem as a binary classification task. The experiments showed that domain-specific word embedding with the Bidirec-tional LSTM based deep model achieved a 93% f1-score while BERT achieved up to 96% f1-score on a combined balanced dataset from available hate speech datasets. Introduction Social media has been used extensively for various purposes, such as advertising, business, news, etc. The idea of allowing users to post anything at any time on social media contributed to the existence of inappropriate content on social media. As a result, these platforms become a fertile environment for this type of content. Hate speech is the most com- mon form of destructive content on social media, and it can come in the form of text, photographs, or video. It is defined as an insult directed at a per-son or group based on characteristics such as color, gender, race, sexual orientation, origin, nationality, religion, or other characteristics (Weber, 2009). Hate speech poses a significant threat to commu-nities, either by instilling hatred in young people against others or by instigating criminal activity or violence against others. Hate speech on the internet is on the rise around the world, with approximately 60% of the global population (4:54 billion) using social media to com- municate (Ltd, 2020). According to studies, ap- proximately 53 percent of Americans have encoun- tered online harassment and hatred (League, 2019). This score is 12 points higher than the findings of a similar survey performed in 2017 (Duggan, 2017). According to Clement (2019), 21% of students frequently encounter hate speech on social media. Thus, the detection of hate content on social media is an essential and necessary requirement for so- cial media platforms. Social media providers work hard to get rid of this content for a safer social en- vironment. Detecting hateful content is considered one of the challenging NLP tasks as the content might target/attack individuals or groups based on various characteristics using different hate terms and phrases (Badjatiya et al., 2017). Social media users often employ abbreviations and ordinary words(not hateful) to express their hate intent implicitly that known as code words to evade from being detected (e.g., using Google to refer to dark skin people), which adds extra diffi- culties to detect hate speech. Many studies have proposed machine learning models to handle this problem by utilizing a wide range of features set and machine learning algorithms for classification (Magu et al., 2017; Agarwal and Sureka, 2015; Jaki and De Smedt, 2019; Hartung et al., 2017). These methods often utilize features that require considerable effort and time to be extracted, such as text-based, profile-based, and community-based features. Other studies have worked on linguistic-based features (e.g., word frequency) and deep learning for classification (de Gibert et al., 2018), or distributional based features (e.g., word embed-ding) and machine learning classifier (Gupta and Waseem, 2017; Badjatiya et al., 2017; Djuric et al., 2015; Nobata et al., 2016). Studies show that distributional features provide a promising result in NLP tasks such as sentiment analysis (Gupta and Waseem, 2017). Recently, deep learning methods also show that it performs well on various NLP problems (Socher et al., 2012). Thus, this study investigates the performance of em- ploying these two methods. Accordingly, this study uses the distributional-based learning method to extract meaningful domain-specific embedding as features and deep learning based on BidirectionalShort Term Memory (BiLSTM) classifier to detect hate speech. The word embedding/ distribu- tional representation in this research is built upon a hate speech corpus of 1; 048; 563 sentences to reach the closest meaningful representation vec-tor of hate words. Then, compare it with the domain- agnostic embedding model such as Google Word2Vec and GloVe under the same classifier. We also assess the performance of detecting hate speech using GoogleÃ¢ÂÂs pre-trained BERT model, which has generally achieved a state-of-the-art for many NLP tasks. The contributions of this research are highlighted as follow: An unsupervised domain-specific word em-bedding model was developed to extract the meaning of commonly used terminology, acronyms, and purposefully misspelled hate words. A comparison between the domain- specific and domain agnostic embedding was provided. The findings show that domain agnostic em-bedding performs slightly better (about 1%), despite the huge difference in the trained cor-pus size. The evaluation of a BiLSTM-based deep model with domain-specific embeddings shows an improvement ranging from 5 to 6 points on available datasets over the state-of-the-art techniques. The evaluation of the BERT language model on the hate speech binary classification task shows an improvement of about 2 points com-pared to the domain-specific word embedding model. The remaining of this paper is constructed as follows: the background section provides back- ground information about hate detection and the used methodologies; the review of literature sec-tion includes most recent studies in the field; the methodology section describes the methods used in this study and its specification; the experiment and result section presents the used datasets, em- bedding models, and results of the experiments; the discussion section includes analysis and obser- vation from the results, and finally the conclusion section summarizes all the findings. Background This section gives an overview of hate speech detec-tion in the field and it provides information about the used methodologies for both of the features and classifiers. 2.1 Hate Speech Detection Several research have attempted to solve the prob- lem of detecting hate speech in general by differ- entiating hate and non-hate speech. (Ribeiro et al., 2017; Djuric et al., 2015). Others have tackled the issue of recognizing certain types of hate speech, such as anti-religious hate speech. (Albadi et al., 2018; Zhang et al., 2018), jihadist (De Smedt et al., 2018; Ferrara et al., 2016; Wei et al., 2016; Gialam- poukidis et al., 2017), sexist and racist (Badjatiya et al., 2017; Pitsilis et al., 2018; Gamback ÃÂ and Sik- dar, 2017). Several platforms have been used to collect datasets from various online resources such as websites or online forums (e.g., 4Chan, Dai- lyStorm), or recent social media platforms (e.g., Twitter, Facebook). Hate speech has been applied also on different languages (e.g., English, Arabic, German). 2.2 Word Embedding Word embedding (Bengio et al., 2003) is a promi-nent natural language processing (NLP) technique that seeks to convey the semantic meaning of a word. It provides a useful numerical description of the term based on its context. The words are repre-sented by a dense vector that can be used in estimat-ing the similarities between the words (Liu, 2018). The word is represented by an N- dimensional vec-tor appropriate to represent the word meaning in a specific language (Mikolov et al., 2013). The word embedding has been widely used in many recent NLP tasks due to its efficiency such as text classification (Gamback ÃÂ and Sikdar, 2017; Lilleberg et al., 2015), document clustering (Ailem et al., 2017), part of speech tagging (Wang et al., 2015), named entity recognition (SiencnikÃÂ, 2015), sentiment anal-ysis (Tang et al., 2014; Wang et al., 2016; Al-Azani and El-Alfy, 2017), and many other problems. The most common pretrained word embedding models are Google Word2Vec, Stanford GloVe and they are described as follow: 2.2.1 Word2Vec Word2Vec is one of the most recently used word embedding models. It is provided by theresearch team (Mikolov et al., 2013). Word2Vec associates each word with a vector-based on its surrounding context from a large corpus. The train- ing process for extracting the word vector has two types, the continuous bag of words model (CBOW), which predicts the target word from its context, and the Skip-Gram model (SG), which predicts the tar- get context from a given word. The feature vector of the word is manipulated and updated accord-ing to each context the word appears in the cor-pus. If the word embedding is trained well, similar words appear close to each other in the dimensional space. The word similarities between the words are measured by the cosine distance between their vec- tors. Google released a vector model called Google Word2Vec that has been trained on a massive cor- pus of over 100 billion words. 2.2.2 GloVe Pennington et al. (2014) provides another popular word embedding model named GloVe (Global Vec- tors for Word Representation). GloVe learns em- beddings using an unsupervised learning algorithm that is trained on a corpus to create the distribu- tional feature vectors. During the learning process, a statistics-based matrix is built to represent the words to words co-occurrence of the corpus. This matrix represents the word vectors. The learning process requires time and space for the matrix con- struction, which is a highly costly process. The difference between GloVe and Word2Vec is in the learning process, Word2Vec is a prediction based model, and GloVe is a count-based model. The GloVe is learned from Wikipedia, web data, Twit-ter, and each model is available with multiple vector dimensions. 2.3 Bidirectional Long Short-Term Memory (BiLSTM) LSTM (Hochreiter and Schmidhuber, 1997) is an enhanced version of the recurrent neural network, which is one of the deep learning models that is designed to capture information from a sequence of information. It differs from the feed-forward neural network in that it has a backward connection. RNN suffers from a vanishing gradient problem that happens when the weights are not updated anymore due to the small value of the received from error function in respect to the current weights in the iteration. The value is vanishing in very long sequences and becomes close to zero. This problem stops RNN from training. LSTM solves this problem by adding an extra interaction cell to preserve long sequence dependencies. Thus, LSTM saves data for long sequences, but it saves the data only from left to right. However, to save sequence data from both directions, a Bidirectional LSTM (BiLSTM) is used. BiLSTM consist of two LSTM, one process the data from left to right and the other in opposite direction then concatenates and flattens both forward and backward LSTM to improve the knowledge of the surrounding context. 2.4 BERT Pre-trained Language Model Bidirectional Encoder Representations from Trans- formers (BERT) (Devlin et al., 2018) is a language model trained on very huge data based on con- textual representations. BERT consists of feature extraction layers, which consist of word embed-ding and layer for the model (e.g., Classification, Question Answering, Named Entity Recognition). BERT is the most recent language model and pro- vides state of the art results in comparison to other language models for various NLP tasks. BERT training procedure of word embedding differs from other word embedding models. It creates a bidirec- tional representation of words that may be learned from both left and right directions. Word embed-ding approaches like Word2Vec and GloVe only examine one direction (either left to right or right to left), resulting in static word representations that do not alter with context. If the wordÃ¢ÂÂs meaning varies depending on the context, GloVe and Word2Vec map the word to only one embedding vector. As a result, Word2Vec and GloVe are referred to as context-free models. BERT is also different from previous language models (e.g., ELMo stands for Embeddings from Language Models (Peters et al., 2018)) in that it manipulates the context in all layers in both directions (left and right). Instead of shal-low combining processes such as concatenating, it use cooperatively conditioningcombine both left and right context. BERT is trained on Books Cor-pus (800M words) and English Wikipedia (2,500M words) (Devlin et al., 2018). Review of Literature It is worth noting that word embedding is an effec- tive approach to a variety of NLP issues. To extract bio-events from the scientific literature, Li et al. (2015) used word embedding. They used multiple sets of features such as, word embedding, BOW + n-gram joint model, and word embedding BOW joint model with SVM classifier and the overall per- formance of word embedding BOW is better than other models on different events, which reached to 77:37% f1-score. The pure word embedding model has lower performance because the dataset size is small. Wu et al. (2015) also used word embedding to distinguish clinical abbreviations as a special case of word sense disambiguation (WSD). The performance of SVM increased when employing word embedding features with an average accuracy of 93%. Hate speech identification is a prevalent issue that has gotten a lot of attention from researchers. Liu (2018) employed domain-specific word em- bedding model trained on the articles from hate speech websites and high centrality usersÃ¢ÂÂ tweets to reach to the semantics of code words used in hate speech. They experimented on CNN, and LSTM models and concluded that CNN performed better than LSTM on tweets due to the length of tweets. The achieved f1-score is 78% given that they ex- perimented on the previous tweet-length 180 char- acters. Gupta and Waseem (2017) evaluate the performance of using hate Word2Vec (i.e., domain- specific) model with Logistic Regression (LR) clas- sifier on three datasets. They achieved up to 91% f1-score. The results showed that domain-specific word embedding has a desirable performance and is suitable for unbalanced classes datasets. Nobata et al. (2016) aimed to detect abusive language using pretrained word embeddings on two domains (finance and news) and regression model for classification, they achieved 60:2% and 64:9% f1-score respectively. The results showed that Google Word2Vec provides better performance with 5% on both domains. Badjatiya et al. (2017) Ã¢ÂÂÃ¢ÂÂemployed deep learning techniques to extract em- bedding features from hate speech text and then used a decision tree model for classification. They reached 93% f1-score using random embeddings initialization that is fed to LSTM to construct fea- tures. The results proved that domain-specific em- bedding can provide better representation of hate words such as Ã¢ÂÂracistÃ¢ÂÂ or Ã¢ÂÂsexistÃ¢ÂÂ words, because it can extract the meaning of frequently used terms by the hate community, domain-specific-based de- tection is a promising method for the detection of hate speech, according to all of the research above. The authors of (Devlin et al., 2018) looked into the BERT modelÃ¢ÂÂs performance on a variety of NLP tasks. On eleven of these tasks, the model produced state-of-the-art results. It improved by 7:7 points in the General Language Understanding Evaluation (GLUE) benchmark, 4:6 points in Multi- Genre Nat-ural Language Inference (MultiNLI), and 1:5 to 5:1 points in the SQuAD various versions question an-swering tests. BERT language model was recently employed in a shared task to detect offensive language (Zhu et al., 2019; Pelicon et al., 2019; Wu et al., 2019). Zhu et al. (2019) fine tuned BERT model for this task and came in third place among competitors. They used 13; 240 in tweets to train the algorithm, with each message categorized as offensive or not offensive. They achieved 83:88% f1-score. Moza- fari et al. (2020) studied the performance of the BERT language model on hate speech detection as a multi-class problem in a recently released work. They employed a BERT basis and a variety of clas- sifiers, including CNN, which provided the highest score that reached to 92% f1-score. Conclusion and Future Work To conclude, BERT design provides an appropriate feature extraction and classification procedure for hate speech detection. BERT combines the benefits of domain agnostic and domain-specific word embedding by train the modelvast data then add an extra layer to trained on domain-specific data (fine-tuning). BERT also saves effort and time for building an embedding model from scratch. However, domain-specific word embedding overcomes BERT model in that it can detect hate terms and abbreviations and intentionally misspellings meaning.