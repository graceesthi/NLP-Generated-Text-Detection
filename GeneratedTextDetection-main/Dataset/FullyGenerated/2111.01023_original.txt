Abstract This paper shows that a popular approach to the supervised embedding of documents for classification, namely, contrastive Word Mover’s Embedding, can be significantly enhanced by adding interpretability. This interpretability is achieved by incorporating a clustering promoting mechanism into the contrastive loss. On several public datasets, we show that our method improves significantly upon existing baselines while providing interpretation to the clusters via identifying a set of keywords that are the most representative of a particular class. Our approach was motivated in part by the need to develop Natural Language Processing (NLP) methods for the novel problem of assessing student work for scientific writing and thinking - a problem that is central to the area of (educational) Learning Sciences (LS). In this context, we show that our approach leads to a meaningful assessment of the student work related to lab reports from a biology class and can help LS researchers gain insights into student understanding and assess evidence of scientific thought processes. Introduction Modern computational methods for Natural Language Processing (NLP) rely on embeddings into metric spaces such as the Euclidean, and more recently non-linear spaces such as the Wasserstein space, to achieve state-of-art performance for various tasks. In these embeddings, the semantic differences and similarities between words and documents, correspond to the distances in the represented space. For embedding into Euclidean spaces, a large body of work is based on Word2vec (Mikolov et al., 2013), where each word is represented as a vector in the Euclidean space. From these word embeddings one can further compute document and sentence embeddings using various models Ramos et al. (2003), Arora et al. (2017), Wang and Kuo (2020), Le and Mikolov (2014), Kiros et al. (2015), Logeswaran and Lee (2018) for higher level NLP tasks. Instead of embedding and comparing documents in the Euclidean space, Word Mover’s Distance (WMD) Kusner et al. (2015) was proposed to measure the similarity between documents in the Wasserstein space Peyré and Cuturi (2018), representing the documents with (empirical) probability distributions. In Huang et al. (2016) WMD is used for supervised learning and more recently in (Yurochkin et al., 2019), for multi-scale representation. To understand how these models work, a lot of effort has been put into aiding interpretability of these embeddings. In Arora et al. (2018) the authors proposed a linear algebraic structure to explain the polysemy of words. Recent works attempted to explain the meaning of each dimension, such as the sparse word embedding Faruqui et al. (2015); Panigrahi et al. (2019) and the POLAR Framework Mathew et al. (2020). To make WMD embeddings interpretable, Xu et al. (2018) proposed an unsupervised topic model in the representation space. In this work our focus is on enabling interpretable supervised WMD embeddings of the documents. Below we summarize the main contributions in this direction. Summary of main contributions - A new approach for contrastive representation learning is proposed via enforcing a clustering promoting mechanism using a set of anchors that in turn are also learned from the data. This, in contrast to previous approaches Huang et al. (2016); Kusner et al. (2015), allows for interpretability, i.e. allows one to determine which words are important for a particular class. Furthermore, compared to the K Nearest Neighbour (KNN), our classification using the learned anchors is faster (O(n) for usual KNN vs O(1) for our NN using anchors), and our method can be generalized to any other supervised contrastive learning. Results on public data sets as well as a on a novel data set evaluating written scientific work by students show the superiority and utility of our method. Discussion of lab report results: The discriminatory words identified by our approach, suggest a good fit with the qualitative differences, namely, claim complexity, scope of evidence, and consistency and closure, used by human coders to make classifications. The words also suggest themes not directly coded for. For example, differences in adjectives reflect differences in claim structure. The importance of adjectives such as positive, negative and relative, reflect the more complex claim structure in high scoring reports. While low scoring reports stated simple claims, high scoring reports compared the relative influence of competing effects (i.e. positive and negative mutations). Another hallmark of high scoring report is qualified or conditional claims that indicate context specificity or uncertainty. The importance of adverbs such as predominantly, largely, and disproportionately, in high-scoring reports, reflects uncertainty, expressed as of probabilistic claims, that were common in these reports. While these properties were not observed from the top words generated by TF-IDF. The predominance of nouns and verbs that describe laboratory procedures (e.g. method, procedure, standardize) in low-scoring reports is an interesting difference not directly coded for by human coders. It is nevertheless consistent with the shift in the laboratory curriculum from an emphasis on reporting on procedures to interpreting and arguing about findings that underlies the shift from low to high scores. Overall these findings suggest that our method captures meaningful qualitative differences originally identified by qualitative researchers